{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9375689,"sourceType":"datasetVersion","datasetId":5687021}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install weaviate-client langchain-text-splitters\n!pip install pymupdf\n!pip install llama-cpp-python","metadata":{"execution":{"iopub.status.busy":"2024-09-16T17:23:59.112213Z","iopub.execute_input":"2024-09-16T17:23:59.112650Z","iopub.status.idle":"2024-09-16T17:24:30.494200Z","shell.execute_reply.started":"2024-09-16T17:23:59.112609Z","shell.execute_reply":"2024-09-16T17:24:30.492678Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Requirement already satisfied: weaviate-client in /opt/conda/lib/python3.10/site-packages (4.8.1)\nRequirement already satisfied: langchain-text-splitters in /opt/conda/lib/python3.10/site-packages (0.3.0)\nRequirement already satisfied: requests<3.0.0,>=2.30.0 in /opt/conda/lib/python3.10/site-packages (from weaviate-client) (2.32.3)\nRequirement already satisfied: httpx<=0.27.0,>=0.25.0 in /opt/conda/lib/python3.10/site-packages (from weaviate-client) (0.27.0)\nRequirement already satisfied: validators==0.34.0 in /opt/conda/lib/python3.10/site-packages (from weaviate-client) (0.34.0)\nRequirement already satisfied: authlib<1.3.2,>=1.2.1 in /opt/conda/lib/python3.10/site-packages (from weaviate-client) (1.3.1)\nRequirement already satisfied: pydantic<3.0.0,>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from weaviate-client) (2.8.2)\nRequirement already satisfied: grpcio<2.0.0,>=1.57.0 in /opt/conda/lib/python3.10/site-packages (from weaviate-client) (1.65.5)\nRequirement already satisfied: grpcio-tools<2.0.0,>=1.57.0 in /opt/conda/lib/python3.10/site-packages (from weaviate-client) (1.66.1)\nRequirement already satisfied: grpcio-health-checking<2.0.0,>=1.57.0 in /opt/conda/lib/python3.10/site-packages (from weaviate-client) (1.66.1)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from langchain-text-splitters) (0.3.0)\nRequirement already satisfied: cryptography in /opt/conda/lib/python3.10/site-packages (from authlib<1.3.2,>=1.2.1->weaviate-client) (42.0.8)\nCollecting protobuf<6.0dev,>=5.26.1 (from grpcio-health-checking<2.0.0,>=1.57.0->weaviate-client)\n  Using cached protobuf-5.28.1-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nCollecting grpcio<2.0.0,>=1.57.0 (from weaviate-client)\n  Using cached grpcio-1.66.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from grpcio-tools<2.0.0,>=1.57.0->weaviate-client) (70.0.0)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<=0.27.0,>=0.25.0->weaviate-client) (4.4.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<=0.27.0,>=0.25.0->weaviate-client) (2024.7.4)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<=0.27.0,>=0.25.0->weaviate-client) (1.0.5)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx<=0.27.0,>=0.25.0->weaviate-client) (3.7)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<=0.27.0,>=0.25.0->weaviate-client) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<=0.27.0,>=0.25.0->weaviate-client) (0.14.0)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-text-splitters) (6.0.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-text-splitters) (1.33)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.117 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-text-splitters) (0.1.121)\nRequirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-text-splitters) (24.1)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-text-splitters) (8.3.0)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-text-splitters) (4.12.2)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.0->weaviate-client) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.0->weaviate-client) (2.20.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (1.26.18)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain-text-splitters) (2.4)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain-text-splitters) (3.10.4)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<=0.27.0,>=0.25.0->weaviate-client) (1.2.0)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography->authlib<1.3.2,>=1.2.1->weaviate-client) (1.16.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography->authlib<1.3.2,>=1.2.1->weaviate-client) (2.22)\nUsing cached grpcio-1.66.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\nUsing cached protobuf-5.28.1-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\nInstalling collected packages: protobuf, grpcio\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n  Attempting uninstall: grpcio\n    Found existing installation: grpcio 1.65.5\n    Uninstalling grpcio-1.65.5:\n      Successfully uninstalled grpcio-1.65.5\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 5.28.1 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 17.0.0 which is incompatible.\ngoogle-ai-generativelanguage 0.6.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.1 which is incompatible.\ngoogle-api-core 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.28.1 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-artifact-registry 1.11.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires protobuf<4.0.0dev,>=3.12.0, but you have protobuf 5.28.1 which is incompatible.\ngoogle-cloud-bigquery-connection 1.15.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.1 which is incompatible.\ngoogle-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 5.28.1 which is incompatible.\ngoogle-cloud-datastore 1.15.5 requires protobuf<4.0.0dev, but you have protobuf 5.28.1 which is incompatible.\ngoogle-cloud-dlp 3.18.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.1 which is incompatible.\ngoogle-cloud-functions 1.16.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.1 which is incompatible.\ngoogle-cloud-iam 2.15.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.1 which is incompatible.\ngoogle-cloud-monitoring 2.21.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.1 which is incompatible.\ngoogle-cloud-pubsub 2.21.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.1 which is incompatible.\ngoogle-cloud-recommendations-ai 0.7.1 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 5.28.1 which is incompatible.\ngoogle-cloud-resource-manager 1.12.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.1 which is incompatible.\ngoogle-cloud-spanner 3.47.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.2, but you have protobuf 5.28.1 which is incompatible.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.1 which is incompatible.\ngoogle-cloud-vision 2.8.0 requires protobuf<4.0.0dev,>=3.19.0, but you have protobuf 5.28.1 which is incompatible.\ngrpc-google-iam-v1 0.12.7 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 5.28.1 which is incompatible.\nkfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 5.28.1 which is incompatible.\nopentelemetry-proto 1.25.0 requires protobuf<5.0,>=3.19, but you have protobuf 5.28.1 which is incompatible.\nproto-plus 1.23.0 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 5.28.1 which is incompatible.\ntensorboard-plugin-profile 2.15.1 requires protobuf<5.0.0dev,>=3.19.6, but you have protobuf 5.28.1 which is incompatible.\ntensorflow 2.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.1 which is incompatible.\ntensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 5.28.1 which is incompatible.\ntensorflow-serving-api 2.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.1 which is incompatible.\ntensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 5.28.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed grpcio-1.66.1 protobuf-5.28.1\nRequirement already satisfied: pymupdf in /opt/conda/lib/python3.10/site-packages (1.24.10)\nRequirement already satisfied: PyMuPDFb==1.24.10 in /opt/conda/lib/python3.10/site-packages (from pymupdf) (1.24.10)\n^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: llama-cpp-python in /opt/conda/lib/python3.10/site-packages (0.2.90)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (4.12.2)\nRequirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (1.26.4)\nRequirement already satisfied: diskcache>=5.6.1 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (5.6.3)\nRequirement already satisfied: jinja2>=2.11.3 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import weaviate\n\nauth_config = weaviate.AuthApiKey(api_key=\"hbm9Ln9sDMhd6bqrYPG9h1mIwZdgH0fnmURj\")\n\nclient = weaviate.Client(\n  url=\"https://gjrdo8ezt7wdojg288fga.c0.asia-southeast1.gcp.weaviate.cloud\",\n  auth_client_secret=auth_config\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T17:24:30.496788Z","iopub.execute_input":"2024-09-16T17:24:30.497263Z","iopub.status.idle":"2024-09-16T17:24:30.706092Z","shell.execute_reply.started":"2024-09-16T17:24:30.497219Z","shell.execute_reply":"2024-09-16T17:24:30.704792Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/weaviate/__init__.py:144: DeprecationWarning: Dep010: Importing AuthApiKey from weaviate is deprecated. Import AuthApiKey from its module: weaviate.auth\n  _Warnings.root_module_import(name, map_[name])\n/tmp/ipykernel_36/2668767791.py:5: DeprecationWarning: \nPython client v3 `weaviate.Client(...)` connections and methods are deprecated and will\n            be removed by 2024-11-30.\n\n            Upgrade your code to use Python client v4 `weaviate.WeaviateClient` connections and methods.\n                - For Python Client v4 usage, see: https://weaviate.io/developers/weaviate/client-libraries/python\n                - For code migration, see: https://weaviate.io/developers/weaviate/client-libraries/python/v3_v4_migration\n\n            If you have to use v3 code, install the v3 client and pin the v3 dependency in your requirements file: `weaviate-client>=3.26.7;<4.0.0`\n  client = weaviate.Client(\n/opt/conda/lib/python3.10/site-packages/weaviate/warnings.py:162: DeprecationWarning: Dep016: Python client v3 `weaviate.Client(...)` connections and methods are deprecated and will\n            be removed by 2024-11-30.\n\n            Upgrade your code to use Python client v4 `weaviate.WeaviateClient` connections and methods.\n                - For Python Client v4 usage, see: https://weaviate.io/developers/weaviate/client-libraries/python\n                - For code migration, see: https://weaviate.io/developers/weaviate/client-libraries/python/v3_v4_migration\n\n            If you have to use v3 code, install the v3 client and pin the v3 dependency in your requirements file: `weaviate-client>=3.26.7;<4.0.0`\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"!wget https://huggingface.co/CompendiumLabs/bge-small-en-v1.5-gguf/resolve/main/bge-small-en-v1.5-f16.gguf\n!wget https://huggingface.co/alugupta/Duniya_ka_papa_model/resolve/main/Main-Model-7.2B-Q5_K_M.gguf","metadata":{"execution":{"iopub.status.busy":"2024-09-16T17:24:30.707791Z","iopub.execute_input":"2024-09-16T17:24:30.708309Z","iopub.status.idle":"2024-09-16T17:24:37.794839Z","shell.execute_reply.started":"2024-09-16T17:24:30.708262Z","shell.execute_reply":"2024-09-16T17:24:37.793500Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"--2024-09-16 17:24:31--  https://huggingface.co/CompendiumLabs/bge-small-en-v1.5-gguf/resolve/main/bge-small-en-v1.5-f16.gguf\nResolving huggingface.co (huggingface.co)... 54.230.71.2, 54.230.71.56, 54.230.71.103, ...\nConnecting to huggingface.co (huggingface.co)|54.230.71.2|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://cdn-lfs-us-1.huggingface.co/repos/4f/84/4f84a63d076c5beeed8907d579c1c59287bb13e0da4fa48235d5a0d146ada7e6/f0b2fef971e8366438bfd2d9aefea1b0115919389448806d290237f638bae999?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27bge-small-en-v1.5-f16.gguf%3B+filename%3D%22bge-small-en-v1.5-f16.gguf%22%3B&Expires=1726766671&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNjc2NjY3MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzRmLzg0LzRmODRhNjNkMDc2YzViZWVlZDg5MDdkNTc5YzFjNTkyODdiYjEzZTBkYTRmYTQ4MjM1ZDVhMGQxNDZhZGE3ZTYvZjBiMmZlZjk3MWU4MzY2NDM4YmZkMmQ5YWVmZWExYjAxMTU5MTkzODk0NDg4MDZkMjkwMjM3ZjYzOGJhZTk5OT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=he21xJYYq87DDALVRdM9P%7EnzNDW%7EYaPxBf0dYeaVtmnoRZSk8bBcub1UCWo8FNjaVfpNG%7E7CRNq1%7ELLESmId5PQaT8Rts-EFci61ltFaG3YGXSe3-LKMQ%7EqCm2etcGPl9jpYLoUxGQZ35xq-SMlcEPE-Azw5bzQy%7Eixi0HllIQVGAKHFhk3v-Q98AZcU6jT6aWMkxx9oQHFFw%7ENSHMSexxkK9UgBBYHlXDtK1M5RFErmnctPzoQbmAdiPjZF2ZaZNV3m5qAYDZZQ54rBJ8Du8TrbHa2Ntj8yIYM11YxTnJvNH5bfNEN2dzpRZS9NyaROfvNXZQ57QUisABOT8Tyipg__&Key-Pair-Id=K24J24Z295AEI9 [following]\n--2024-09-16 17:24:32--  https://cdn-lfs-us-1.huggingface.co/repos/4f/84/4f84a63d076c5beeed8907d579c1c59287bb13e0da4fa48235d5a0d146ada7e6/f0b2fef971e8366438bfd2d9aefea1b0115919389448806d290237f638bae999?response-content-disposition=inline%3B+filename*%3DUTF-8''bge-small-en-v1.5-f16.gguf%3B+filename%3D%22bge-small-en-v1.5-f16.gguf%22%3B&Expires=1726766671&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNjc2NjY3MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzRmLzg0LzRmODRhNjNkMDc2YzViZWVlZDg5MDdkNTc5YzFjNTkyODdiYjEzZTBkYTRmYTQ4MjM1ZDVhMGQxNDZhZGE3ZTYvZjBiMmZlZjk3MWU4MzY2NDM4YmZkMmQ5YWVmZWExYjAxMTU5MTkzODk0NDg4MDZkMjkwMjM3ZjYzOGJhZTk5OT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=he21xJYYq87DDALVRdM9P~nzNDW~YaPxBf0dYeaVtmnoRZSk8bBcub1UCWo8FNjaVfpNG~7CRNq1~LLESmId5PQaT8Rts-EFci61ltFaG3YGXSe3-LKMQ~qCm2etcGPl9jpYLoUxGQZ35xq-SMlcEPE-Azw5bzQy~ixi0HllIQVGAKHFhk3v-Q98AZcU6jT6aWMkxx9oQHFFw~NSHMSexxkK9UgBBYHlXDtK1M5RFErmnctPzoQbmAdiPjZF2ZaZNV3m5qAYDZZQ54rBJ8Du8TrbHa2Ntj8yIYM11YxTnJvNH5bfNEN2dzpRZS9NyaROfvNXZQ57QUisABOT8Tyipg__&Key-Pair-Id=K24J24Z295AEI9\nResolving cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)... 13.35.166.59, 13.35.166.108, 13.35.166.55, ...\nConnecting to cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)|13.35.166.59|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 67308128 (64M) [binary/octet-stream]\nSaving to: 'bge-small-en-v1.5-f16.gguf.1'\n\nbge-small-en-v1.5-f 100%[===================>]  64.19M  61.3MB/s    in 1.0s    \n\n2024-09-16 17:24:33 (61.3 MB/s) - 'bge-small-en-v1.5-f16.gguf.1' saved [67308128/67308128]\n\n--2024-09-16 17:24:34--  https://huggingface.co/alugupta/Duniya_ka_papa_model/resolve/main/Main-Model-7.2B-Q5_K_M.gguf\nResolving huggingface.co (huggingface.co)... 54.230.71.103, 54.230.71.2, 54.230.71.56, ...\nConnecting to huggingface.co (huggingface.co)|54.230.71.103|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://cdn-lfs-us-1.huggingface.co/repos/07/29/07290bf76fcbcaa4462f0cf22a5f0646751b86f8c7f1e66f20c9f3edfe7db51b/8cfa0b55a9f91fb408c730e72247b9331b18127c7ec3686a2dc3fbfa7a4704a9?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Main-Model-7.2B-Q5_K_M.gguf%3B+filename%3D%22Main-Model-7.2B-Q5_K_M.gguf%22%3B&Expires=1726766674&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNjc2NjY3NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzA3LzI5LzA3MjkwYmY3NmZjYmNhYTQ0NjJmMGNmMjJhNWYwNjQ2NzUxYjg2ZjhjN2YxZTY2ZjIwYzlmM2VkZmU3ZGI1MWIvOGNmYTBiNTVhOWY5MWZiNDA4YzczMGU3MjI0N2I5MzMxYjE4MTI3YzdlYzM2ODZhMmRjM2ZiZmE3YTQ3MDRhOT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=OSuqFklq61sJkK4Ut2ROJX4v64j-8jPMgUf4dQhKmqAUz7OWikUJM5ZWKvXwDUkp3ngBqdpANVTwwJ8uJy9%7E%7Emuh8HOvAGOdeaKpSQSid48kFEheSqwTdvTqEEpiJJf%7ECJ%7Eyd%7Ez6F1SqQjM7WWBd4blbBg6i%7EFcUYIMAvsOM0EtevJuBzkh68wTzmio-e9i-J7ryrmPBTzTVRi7CI8NXfGQErpXcL9dGp-r7KiwC-1Y8G-Mf33718EbQlqRyGYEMAvH3WuesBFnhIClKWHAl0bDHo4g2pXSvJze8EPCDPvK327AQQVDsLQS3fY3EpE%7EsOC6LiMT9BegpO82xlwOR9g__&Key-Pair-Id=K24J24Z295AEI9 [following]\n--2024-09-16 17:24:34--  https://cdn-lfs-us-1.huggingface.co/repos/07/29/07290bf76fcbcaa4462f0cf22a5f0646751b86f8c7f1e66f20c9f3edfe7db51b/8cfa0b55a9f91fb408c730e72247b9331b18127c7ec3686a2dc3fbfa7a4704a9?response-content-disposition=inline%3B+filename*%3DUTF-8''Main-Model-7.2B-Q5_K_M.gguf%3B+filename%3D%22Main-Model-7.2B-Q5_K_M.gguf%22%3B&Expires=1726766674&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNjc2NjY3NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzA3LzI5LzA3MjkwYmY3NmZjYmNhYTQ0NjJmMGNmMjJhNWYwNjQ2NzUxYjg2ZjhjN2YxZTY2ZjIwYzlmM2VkZmU3ZGI1MWIvOGNmYTBiNTVhOWY5MWZiNDA4YzczMGU3MjI0N2I5MzMxYjE4MTI3YzdlYzM2ODZhMmRjM2ZiZmE3YTQ3MDRhOT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=OSuqFklq61sJkK4Ut2ROJX4v64j-8jPMgUf4dQhKmqAUz7OWikUJM5ZWKvXwDUkp3ngBqdpANVTwwJ8uJy9~~muh8HOvAGOdeaKpSQSid48kFEheSqwTdvTqEEpiJJf~CJ~yd~z6F1SqQjM7WWBd4blbBg6i~FcUYIMAvsOM0EtevJuBzkh68wTzmio-e9i-J7ryrmPBTzTVRi7CI8NXfGQErpXcL9dGp-r7KiwC-1Y8G-Mf33718EbQlqRyGYEMAvH3WuesBFnhIClKWHAl0bDHo4g2pXSvJze8EPCDPvK327AQQVDsLQS3fY3EpE~sOC6LiMT9BegpO82xlwOR9g__&Key-Pair-Id=K24J24Z295AEI9\nResolving cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)... 13.35.166.55, 13.35.166.59, 13.35.166.96, ...\nConnecting to cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)|13.35.166.55|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 5136179008 (4.8G) [binary/octet-stream]\nSaving to: 'Main-Model-7.2B-Q5_K_M.gguf.1'\n\nn-Model-7.2B-Q5_K_M   2%[                    ] 131.31M  49.9MB/s               ^C\n","output_type":"stream"}]},{"cell_type":"code","source":"from llama_cpp import Llama\n\n# Path to your downloaded and quantized .gguf model\nmodel_path = \"./Main-Model-7.2B-Q5_K_M.gguf\"\n\n# Load the model\nmodel = Llama(model_path=model_path, n_ctx=2048)\n\n# Example query to the model\nans=model.create_chat_completion(\n      messages = [\n          {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n          {\n              \"role\": \"user\",\n              \"content\": \"When did India got independence?\"\n          }\n      ]\n)\n\nprint(ans)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T17:24:37.796712Z","iopub.execute_input":"2024-09-16T17:24:37.797179Z","iopub.status.idle":"2024-09-16T17:24:55.858866Z","shell.execute_reply.started":"2024-09-16T17:24:37.797129Z","shell.execute_reply":"2024-09-16T17:24:55.857767Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"llama_model_loader: loaded meta data with 34 key-value pairs and 291 tensors from ./Main-Model-7.2B-Q5_K_M.gguf (version GGUF V3 (latest))\nllama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\nllama_model_loader: - kv   0:                       general.architecture str              = llama\nllama_model_loader: - kv   1:                               general.type str              = model\nllama_model_loader: - kv   2:                               general.name str              = Main Model\nllama_model_loader: - kv   3:                         general.size_label str              = 7.2B\nllama_model_loader: - kv   4:                            general.license str              = apache-2.0\nllama_model_loader: - kv   5:                   general.base_model.count u32              = 1\nllama_model_loader: - kv   6:                  general.base_model.0.name str              = Mistral 7B v0.3\nllama_model_loader: - kv   7:               general.base_model.0.version str              = v0.3\nllama_model_loader: - kv   8:          general.base_model.0.organization str              = Mistralai\nllama_model_loader: - kv   9:              general.base_model.0.repo_url str              = https://huggingface.co/mistralai/Mist...\nllama_model_loader: - kv  10:                          llama.block_count u32              = 32\nllama_model_loader: - kv  11:                       llama.context_length u32              = 32768\nllama_model_loader: - kv  12:                     llama.embedding_length u32              = 4096\nllama_model_loader: - kv  13:                  llama.feed_forward_length u32              = 14336\nllama_model_loader: - kv  14:                 llama.attention.head_count u32              = 32\nllama_model_loader: - kv  15:              llama.attention.head_count_kv u32              = 8\nllama_model_loader: - kv  16:                       llama.rope.freq_base f32              = 1000000.000000\nllama_model_loader: - kv  17:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\nllama_model_loader: - kv  18:                          general.file_type u32              = 17\nllama_model_loader: - kv  19:                           llama.vocab_size u32              = 32768\nllama_model_loader: - kv  20:                 llama.rope.dimension_count u32              = 128\nllama_model_loader: - kv  21:            tokenizer.ggml.add_space_prefix bool             = true\nllama_model_loader: - kv  22:                       tokenizer.ggml.model str              = llama\nllama_model_loader: - kv  23:                         tokenizer.ggml.pre str              = default\nllama_model_loader: - kv  24:                      tokenizer.ggml.tokens arr[str,32768]   = [\"<unk>\", \"<s>\", \"</s>\", \"[INST]\", \"[...\nllama_model_loader: - kv  25:                      tokenizer.ggml.scores arr[f32,32768]   = [-1000.000000, -1000.000000, -1000.00...\nllama_model_loader: - kv  26:                  tokenizer.ggml.token_type arr[i32,32768]   = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\nllama_model_loader: - kv  27:                tokenizer.ggml.bos_token_id u32              = 1\nllama_model_loader: - kv  28:                tokenizer.ggml.eos_token_id u32              = 2\nllama_model_loader: - kv  29:            tokenizer.ggml.unknown_token_id u32              = 0\nllama_model_loader: - kv  30:               tokenizer.ggml.add_bos_token bool             = true\nllama_model_loader: - kv  31:               tokenizer.ggml.add_eos_token bool             = false\nllama_model_loader: - kv  32:                    tokenizer.chat_template str              = {%- if messages[0][\"role\"] == \"system...\nllama_model_loader: - kv  33:               general.quantization_version u32              = 2\nllama_model_loader: - type  f32:   65 tensors\nllama_model_loader: - type q5_K:  193 tensors\nllama_model_loader: - type q6_K:   33 tensors\nllm_load_vocab: special tokens cache size = 771\nllm_load_vocab: token to piece cache size = 0.1731 MB\nllm_load_print_meta: format           = GGUF V3 (latest)\nllm_load_print_meta: arch             = llama\nllm_load_print_meta: vocab type       = SPM\nllm_load_print_meta: n_vocab          = 32768\nllm_load_print_meta: n_merges         = 0\nllm_load_print_meta: vocab_only       = 0\nllm_load_print_meta: n_ctx_train      = 32768\nllm_load_print_meta: n_embd           = 4096\nllm_load_print_meta: n_layer          = 32\nllm_load_print_meta: n_head           = 32\nllm_load_print_meta: n_head_kv        = 8\nllm_load_print_meta: n_rot            = 128\nllm_load_print_meta: n_swa            = 0\nllm_load_print_meta: n_embd_head_k    = 128\nllm_load_print_meta: n_embd_head_v    = 128\nllm_load_print_meta: n_gqa            = 4\nllm_load_print_meta: n_embd_k_gqa     = 1024\nllm_load_print_meta: n_embd_v_gqa     = 1024\nllm_load_print_meta: f_norm_eps       = 0.0e+00\nllm_load_print_meta: f_norm_rms_eps   = 1.0e-05\nllm_load_print_meta: f_clamp_kqv      = 0.0e+00\nllm_load_print_meta: f_max_alibi_bias = 0.0e+00\nllm_load_print_meta: f_logit_scale    = 0.0e+00\nllm_load_print_meta: n_ff             = 14336\nllm_load_print_meta: n_expert         = 0\nllm_load_print_meta: n_expert_used    = 0\nllm_load_print_meta: causal attn      = 1\nllm_load_print_meta: pooling type     = 0\nllm_load_print_meta: rope type        = 0\nllm_load_print_meta: rope scaling     = linear\nllm_load_print_meta: freq_base_train  = 1000000.0\nllm_load_print_meta: freq_scale_train = 1\nllm_load_print_meta: n_ctx_orig_yarn  = 32768\nllm_load_print_meta: rope_finetuned   = unknown\nllm_load_print_meta: ssm_d_conv       = 0\nllm_load_print_meta: ssm_d_inner      = 0\nllm_load_print_meta: ssm_d_state      = 0\nllm_load_print_meta: ssm_dt_rank      = 0\nllm_load_print_meta: ssm_dt_b_c_rms   = 0\nllm_load_print_meta: model type       = 7B\nllm_load_print_meta: model ftype      = Q5_K - Medium\nllm_load_print_meta: model params     = 7.25 B\nllm_load_print_meta: model size       = 4.78 GiB (5.67 BPW) \nllm_load_print_meta: general.name     = Main Model\nllm_load_print_meta: BOS token        = 1 '<s>'\nllm_load_print_meta: EOS token        = 2 '</s>'\nllm_load_print_meta: UNK token        = 0 '<unk>'\nllm_load_print_meta: LF token         = 781 '<0x0A>'\nllm_load_print_meta: max token length = 48\nllm_load_tensors: ggml ctx size =    0.14 MiB\nllm_load_tensors:        CPU buffer size =  4897.52 MiB\n...................................................................................................\nllama_new_context_with_model: n_ctx      = 2048\nllama_new_context_with_model: n_batch    = 512\nllama_new_context_with_model: n_ubatch   = 512\nllama_new_context_with_model: flash_attn = 0\nllama_new_context_with_model: freq_base  = 1000000.0\nllama_new_context_with_model: freq_scale = 1\nllama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\nllama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\nllama_new_context_with_model:        CPU  output buffer size =     0.13 MiB\nllama_new_context_with_model:        CPU compute buffer size =   164.01 MiB\nllama_new_context_with_model: graph nodes  = 1030\nllama_new_context_with_model: graph splits = 1\nAVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \nModel metadata: {'general.quantization_version': '2', 'tokenizer.chat_template': '{%- if messages[0][\"role\"] == \"system\" %}\\n    {%- set system_message = messages[0][\"content\"] %}\\n    {%- set loop_messages = messages[1:] %}\\n{%- else %}\\n    {%- set loop_messages = messages %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n{%- set user_messages = loop_messages | selectattr(\"role\", \"equalto\", \"user\") | list %}\\n\\n{#- This block checks for alternating user/assistant messages, skipping tool calling messages #}\\n{%- set ns = namespace() %}\\n{%- set ns.index = 0 %}\\n{%- for message in loop_messages %}\\n    {%- if not (message.role == \"tool\" or message.role == \"tool_results\" or (message.tool_calls is defined and message.tool_calls is not none)) %}\\n        {%- if (message[\"role\"] == \"user\") != (ns.index % 2 == 0) %}\\n            {{- raise_exception(\"After the optional system message, conversation roles must alternate user/assistant/user/assistant/...\") }}\\n        {%- endif %}\\n        {%- set ns.index = ns.index + 1 %}\\n    {%- endif %}\\n{%- endfor %}\\n\\n{{- bos_token }}\\n{%- for message in loop_messages %}\\n    {%- if message[\"role\"] == \"user\" %}\\n        {%- if tools is not none and (message == user_messages[-1]) %}\\n            {{- \"[AVAILABLE_TOOLS] [\" }}\\n            {%- for tool in tools %}\\n                {%- set tool = tool.function %}\\n                {{- \\'{\"type\": \"function\", \"function\": {\\' }}\\n                {%- for key, val in tool.items() if key != \"return\" %}\\n                    {%- if val is string %}\\n                        {{- \\'\"\\' + key + \\'\": \"\\' + val + \\'\"\\' }}\\n                    {%- else %}\\n                        {{- \\'\"\\' + key + \\'\": \\' + val|tojson }}\\n                    {%- endif %}\\n                    {%- if not loop.last %}\\n                        {{- \", \" }}\\n                    {%- endif %}\\n                {%- endfor %}\\n                {{- \"}}\" }}\\n                {%- if not loop.last %}\\n                    {{- \", \" }}\\n                {%- else %}\\n                    {{- \"]\" }}\\n                {%- endif %}\\n            {%- endfor %}\\n            {{- \"[/AVAILABLE_TOOLS]\" }}\\n            {%- endif %}\\n        {%- if loop.last and system_message is defined %}\\n            {{- \"[INST] \" + system_message + \"\\\\n\\\\n\" + message[\"content\"] + \"[/INST]\" }}\\n        {%- else %}\\n            {{- \"[INST] \" + message[\"content\"] + \"[/INST]\" }}\\n        {%- endif %}\\n    {%- elif message.tool_calls is defined and message.tool_calls is not none %}\\n        {{- \"[TOOL_CALLS] [\" }}\\n        {%- for tool_call in message.tool_calls %}\\n            {%- set out = tool_call.function|tojson %}\\n            {{- out[:-1] }}\\n            {%- if not tool_call.id is defined or tool_call.id|length != 9 %}\\n                {{- raise_exception(\"Tool call IDs should be alphanumeric strings with length 9!\") }}\\n            {%- endif %}\\n            {{- \\', \"id\": \"\\' + tool_call.id + \\'\"}\\' }}\\n            {%- if not loop.last %}\\n                {{- \", \" }}\\n            {%- else %}\\n                {{- \"]\" + eos_token }}\\n            {%- endif %}\\n        {%- endfor %}\\n    {%- elif message[\"role\"] == \"assistant\" %}\\n        {{- \" \" + message[\"content\"]|trim + eos_token}}\\n    {%- elif message[\"role\"] == \"tool_results\" or message[\"role\"] == \"tool\" %}\\n        {%- if message.content is defined and message.content.content is defined %}\\n            {%- set content = message.content.content %}\\n        {%- else %}\\n            {%- set content = message.content %}\\n        {%- endif %}\\n        {{- \\'[TOOL_RESULTS] {\"content\": \\' + content|string + \", \" }}\\n        {%- if not message.tool_call_id is defined or message.tool_call_id|length != 9 %}\\n            {{- raise_exception(\"Tool call IDs should be alphanumeric strings with length 9!\") }}\\n        {%- endif %}\\n        {{- \\'\"call_id\": \"\\' + message.tool_call_id + \\'\"}[/TOOL_RESULTS]\\' }}\\n    {%- else %}\\n        {{- raise_exception(\"Only user and assistant roles are supported, with the exception of an initial optional system message!\") }}\\n    {%- endif %}\\n{%- endfor %}\\n', 'llama.embedding_length': '4096', 'general.base_model.0.repo_url': 'https://huggingface.co/mistralai/Mistral-7B-v0.3', 'general.license': 'apache-2.0', 'tokenizer.ggml.add_bos_token': 'true', 'general.size_label': '7.2B', 'general.type': 'model', 'general.base_model.0.version': 'v0.3', 'llama.attention.head_count_kv': '8', 'general.base_model.0.name': 'Mistral 7B v0.3', 'llama.context_length': '32768', 'general.architecture': 'llama', 'general.base_model.0.organization': 'Mistralai', 'general.base_model.count': '1', 'llama.feed_forward_length': '14336', 'llama.block_count': '32', 'llama.attention.head_count': '32', 'general.name': 'Main Model', 'tokenizer.ggml.bos_token_id': '1', 'llama.rope.freq_base': '1000000.000000', 'general.file_type': '17', 'tokenizer.ggml.pre': 'default', 'llama.vocab_size': '32768', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.add_space_prefix': 'true', 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.model': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.unknown_token_id': '0'}\nAvailable chat formats from metadata: chat_template.default\nUsing gguf chat template: {%- if messages[0][\"role\"] == \"system\" %}\n    {%- set system_message = messages[0][\"content\"] %}\n    {%- set loop_messages = messages[1:] %}\n{%- else %}\n    {%- set loop_messages = messages %}\n{%- endif %}\n{%- if not tools is defined %}\n    {%- set tools = none %}\n{%- endif %}\n{%- set user_messages = loop_messages | selectattr(\"role\", \"equalto\", \"user\") | list %}\n\n{#- This block checks for alternating user/assistant messages, skipping tool calling messages #}\n{%- set ns = namespace() %}\n{%- set ns.index = 0 %}\n{%- for message in loop_messages %}\n    {%- if not (message.role == \"tool\" or message.role == \"tool_results\" or (message.tool_calls is defined and message.tool_calls is not none)) %}\n        {%- if (message[\"role\"] == \"user\") != (ns.index % 2 == 0) %}\n            {{- raise_exception(\"After the optional system message, conversation roles must alternate user/assistant/user/assistant/...\") }}\n        {%- endif %}\n        {%- set ns.index = ns.index + 1 %}\n    {%- endif %}\n{%- endfor %}\n\n{{- bos_token }}\n{%- for message in loop_messages %}\n    {%- if message[\"role\"] == \"user\" %}\n        {%- if tools is not none and (message == user_messages[-1]) %}\n            {{- \"[AVAILABLE_TOOLS] [\" }}\n            {%- for tool in tools %}\n                {%- set tool = tool.function %}\n                {{- '{\"type\": \"function\", \"function\": {' }}\n                {%- for key, val in tool.items() if key != \"return\" %}\n                    {%- if val is string %}\n                        {{- '\"' + key + '\": \"' + val + '\"' }}\n                    {%- else %}\n                        {{- '\"' + key + '\": ' + val|tojson }}\n                    {%- endif %}\n                    {%- if not loop.last %}\n                        {{- \", \" }}\n                    {%- endif %}\n                {%- endfor %}\n                {{- \"}}\" }}\n                {%- if not loop.last %}\n                    {{- \", \" }}\n                {%- else %}\n                    {{- \"]\" }}\n                {%- endif %}\n            {%- endfor %}\n            {{- \"[/AVAILABLE_TOOLS]\" }}\n            {%- endif %}\n        {%- if loop.last and system_message is defined %}\n            {{- \"[INST] \" + system_message + \"\\n\\n\" + message[\"content\"] + \"[/INST]\" }}\n        {%- else %}\n            {{- \"[INST] \" + message[\"content\"] + \"[/INST]\" }}\n        {%- endif %}\n    {%- elif message.tool_calls is defined and message.tool_calls is not none %}\n        {{- \"[TOOL_CALLS] [\" }}\n        {%- for tool_call in message.tool_calls %}\n            {%- set out = tool_call.function|tojson %}\n            {{- out[:-1] }}\n            {%- if not tool_call.id is defined or tool_call.id|length != 9 %}\n                {{- raise_exception(\"Tool call IDs should be alphanumeric strings with length 9!\") }}\n            {%- endif %}\n            {{- ', \"id\": \"' + tool_call.id + '\"}' }}\n            {%- if not loop.last %}\n                {{- \", \" }}\n            {%- else %}\n                {{- \"]\" + eos_token }}\n            {%- endif %}\n        {%- endfor %}\n    {%- elif message[\"role\"] == \"assistant\" %}\n        {{- \" \" + message[\"content\"]|trim + eos_token}}\n    {%- elif message[\"role\"] == \"tool_results\" or message[\"role\"] == \"tool\" %}\n        {%- if message.content is defined and message.content.content is defined %}\n            {%- set content = message.content.content %}\n        {%- else %}\n            {%- set content = message.content %}\n        {%- endif %}\n        {{- '[TOOL_RESULTS] {\"content\": ' + content|string + \", \" }}\n        {%- if not message.tool_call_id is defined or message.tool_call_id|length != 9 %}\n            {{- raise_exception(\"Tool call IDs should be alphanumeric strings with length 9!\") }}\n        {%- endif %}\n        {{- '\"call_id\": \"' + message.tool_call_id + '\"}[/TOOL_RESULTS]' }}\n    {%- else %}\n        {{- raise_exception(\"Only user and assistant roles are supported, with the exception of an initial optional system message!\") }}\n    {%- endif %}\n{%- endfor %}\n\nUsing chat eos_token: </s>\nUsing chat bos_token: <s>\n\nllama_print_timings:        load time =    4530.61 ms\nllama_print_timings:      sample time =       1.71 ms /    30 runs   (    0.06 ms per token, 17533.61 tokens per second)\nllama_print_timings: prompt eval time =    4530.50 ms /    17 tokens (  266.50 ms per token,     3.75 tokens per second)\nllama_print_timings:        eval time =   12467.45 ms /    29 runs   (  429.91 ms per token,     2.33 tokens per second)\nllama_print_timings:       total time =   17025.62 ms /    46 tokens\n","output_type":"stream"},{"name":"stdout","text":"{'id': 'chatcmpl-aee2d107-a9aa-495d-94ec-49b06aa37eb5', 'object': 'chat.completion', 'created': 1726507478, 'model': './Main-Model-7.2B-Q5_K_M.gguf', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': ' India gained independence from British rule on August 15, 1947. This day is celebrated as Independence Day in India.'}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 17, 'completion_tokens': 29, 'total_tokens': 46}}\n","output_type":"stream"}]},{"cell_type":"code","source":"import pymupdf\ntext = \"\"\n# Open a document\ndoc = pymupdf.open(\"/kaggle/input/testing/DIGITAL FORENSICS.pdf\")\n\n# Extract all the text from the pdf document\nfor page in doc:\n    result = page.get_text()\n    text += result","metadata":{"execution":{"iopub.status.busy":"2024-09-16T17:24:55.862211Z","iopub.execute_input":"2024-09-16T17:24:55.862587Z","iopub.status.idle":"2024-09-16T17:24:55.940466Z","shell.execute_reply.started":"2024-09-16T17:24:55.862548Z","shell.execute_reply":"2024-09-16T17:24:55.939340Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from langchain_text_splitters import RecursiveCharacterTextSplitter\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=300,\n    chunk_overlap=50,\n    length_function=len,\n    is_separator_regex=False\n)\n\ndocuments = text_splitter.create_documents([text])","metadata":{"execution":{"iopub.status.busy":"2024-09-16T17:24:55.941978Z","iopub.execute_input":"2024-09-16T17:24:55.942430Z","iopub.status.idle":"2024-09-16T17:24:55.954866Z","shell.execute_reply.started":"2024-09-16T17:24:55.942383Z","shell.execute_reply":"2024-09-16T17:24:55.953499Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"print(documents)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T17:24:55.956143Z","iopub.execute_input":"2024-09-16T17:24:55.956484Z","iopub.status.idle":"2024-09-16T17:24:55.972230Z","shell.execute_reply.started":"2024-09-16T17:24:55.956449Z","shell.execute_reply":"2024-09-16T17:24:55.971104Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"[Document(metadata={}, page_content='DIGITAL FORENSICS \\nA project submitted in partial fulfilment of the \\nRequirements of the award of the degree of \\nBachelor of Technology \\nIn \\nCOMPUTER SCIENCE AND ENGINEERING \\n \\nSubmitted by: Mohit Singh and Ayush Dwibedy \\nRoll number: 12211003 and 12211001 \\nSupervised by: Dr. Bhupesh Singh Bhati'), Document(metadata={}, page_content='Supervised by: Dr. Bhupesh Singh Bhati \\nINDIAN INSTITUTE OF INFORMATION \\nTECHNOLOGY, \\nSONEPAT – 131001, HARYANA, INDIA \\nACKNOWLEDGEMENTS \\n \\n \\nThe success and the outcome of this project required ceaseless guidance and \\nassistance, my team members and I are extremely privileged to have got this all'), Document(metadata={}, page_content='along the project. \\n \\nWe would like to take this opportunity to acknowledge all the people who have \\nhelped us whole heartedly in every stage of this project. \\n \\nWe are indebtedly grateful to (Dr.) Bhupesh Singh Bhati, Assistant professor,'), Document(metadata={}, page_content='IIIT SONEPAT for providing this opportunity in the first place and giving us all \\nthe support and guidance possible, in spite of having a busy schedule. \\n \\nMohit Singh and Ayush Dwibedy \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nSELF DECLARATION'), Document(metadata={}, page_content='SELF DECLARATION \\n \\n \\nI hereby state that work contained in the project titled ”DIGITAL FORENSICS” \\nis original. I have followed the standards of the project ethics to the best of my \\nabilities. I have acknowledged all sources of knowledge which I have used in \\nthe project.'), Document(metadata={}, page_content='the project. \\n \\n \\n \\nName of team lead: Mohit Singh \\nRoll number: 12211003 \\nName of member: Ayush Dwibedy \\nRoll number: 12211001 \\nDepartment of Computer Science and Engineering, \\nIndian Institute of Information Technology, \\nSonepat-131001, Haryana, India \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nCERTIFICATE'), Document(metadata={}, page_content='CERTIFICATE \\n \\n \\nThis is to certify that Mr. Mohit Singh has worked on this project entitled \\n“DIGITAL FORENSICS” under my supervision and guidance. \\n \\nThe contents of the project, being submitted to the Department of Computer'), Document(metadata={}, page_content='Science and Engineering, IIIT Sonepat, Haryana, for the award of the degree of \\nB. Tech in Computer Science and Engineering, are original and carried out by \\ncandidate himself. This project has not been submitted in full or part for award'), Document(metadata={}, page_content='of any other degree or diploma to this or any other university. \\n \\n \\n \\nDr. Bhupesh Singh Bhati \\nSupervisor \\n \\nDepartment of Computer Science and Engineering \\nIndia Institute of Information Technology, \\nSonepat-131001, Haryana, India \\n \\n \\n \\n \\n \\n \\n \\n \\nABSTRACT \\n \\n \\nName of team lead: Mohit Singh'), Document(metadata={}, page_content='ABSTRACT \\n \\n \\nName of team lead: Mohit Singh \\nRoll number: 12211003 \\nName of member: Ayush Dwibedy \\nRoll number: 12211001 \\nDepartment of Computer Science and Engineering \\nIndian Institute of Information Technology, Sonepat \\n \\nProject Title: Digital Forensics'), Document(metadata={}, page_content='Project Title: Digital Forensics \\nName of project supervisor: Dr. Bhupesh Singh Bhati \\nMonth and year of the project submission: May, 2024 \\n  \\nThis project investigates the potential of Autopsy, an open-source digital'), Document(metadata={}, page_content=\"forensics tool, in recovering deleted data from hard drives linked to criminal \\nactivities. Through a blend of controlled experiments and practical case studies, \\nAutopsy's efficacy in retrieving a diverse range of file types is evaluated. While\"), Document(metadata={}, page_content=\"showcasing its proficiency in unearthing critical evidence, the study also \\nilluminates persistent challenges such as encrypted files and fragmented data. \\nDespite these hurdles, Autopsy emerges as a vital asset in law enforcement's\"), Document(metadata={}, page_content='arsenal against cybercrime, playing a pivotal role in upholding justice in the \\ndigital age. \\n \\n \\n \\n \\n \\n \\nTABLE OF CONTENTS \\n \\nChapter 1 Introduction \\n1 \\n \\n1.1 \\nIntroduction \\n2 \\n \\n1.2 \\nProblem Outline \\n2 \\n \\n1.3 \\nProject Methodology \\n3 \\n \\n1.4 \\nScope of Project \\n4 \\n \\n1.5 \\nLimitations \\n5'), Document(metadata={}, page_content='1.4 \\nScope of Project \\n4 \\n \\n1.5 \\nLimitations \\n5 \\nChapter 2 What is Digital Forensics? \\n7 \\n \\n2.1 \\nDigital Forensics \\n8 \\n \\n2.2 \\nType of Digital Forensics \\n9 \\n \\n2.3 \\nAutopsy Software \\n10 \\nChapter 3 Implementation \\n12 \\n \\n3.1 \\nFamiliarization with Autopsy \\n13 \\n \\n3.2 \\nData acquisition and \\nPreservation'), Document(metadata={}, page_content='13 \\n \\n3.2 \\nData acquisition and \\nPreservation \\n14 \\n \\n3.3 \\nData Recovery \\n16 \\n \\n3.4 \\nAnalysis \\n22 \\nChapter 4 Result and Conclusion \\n25 \\n \\n4.1 \\nValidation and Interpretation \\n26 \\n \\n4.2 \\nDocumentation and Reporting 27 \\n \\n4.3 \\nAnalysis and Conclusion \\n28 \\n \\nReferences \\n29 \\n1'), Document(metadata={}, page_content='28 \\n \\nReferences \\n29 \\n1 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nChapter 1 \\nIntroduction \\n \\n \\n \\n \\n \\n \\n \\n2 \\n \\n1.1 INTRODUCTION \\n \\nBrief introduction to the topic: \\n \\nThis project investigates the potential of Autopsy, an open-source digital'), Document(metadata={}, page_content=\"forensics tool, in recovering deleted data from hard drives linked to criminal \\nactivities. Through a blend of controlled experiments and practical case studies, \\nAutopsy's efficacy in retrieving a diverse range of file types is evaluated. While\"), Document(metadata={}, page_content=\"showcasing its proficiency in unearthing critical evidence, the study also \\nilluminates persistent challenges such as encrypted files and fragmented data. \\nDespite these hurdles, Autopsy emerges as a vital asset in law enforcement's\"), Document(metadata={}, page_content='arsenal against cybercrime, playing a pivotal role in upholding justice in the \\ndigital age. \\n \\n1.2 PROBLEM OUTLINE \\n \\nThe project aims to address the effectiveness and challenges of utilizing \\nAutopsy, an open-source digital forensics tool, in recovering deleted data from'), Document(metadata={}, page_content=\"hard drives associated with criminal activities. Through a combination of \\ncontrolled experiments and practical case studies, the study seeks to evaluate \\nAutopsy's capability in retrieving various file types crucial for forensic \\ninvestigations.\"), Document(metadata={}, page_content=\"investigations. \\n \\nKey objectives include assessing Autopsy's proficiency in uncovering critical \\nevidence, analysing persistent obstacles such as encrypted files and data \\nfragmentation, and highlighting its significance as a valuable asset in combating\"), Document(metadata={}, page_content=\"cybercrime. By examining Autopsy's role in contemporary criminal \\ninvestigations, the project aims to provide insights into the evolving landscape \\nof digital forensics and underscore the importance of ongoing tool development \\nto ensure effective law enforcement in the digital realm. \\n \\n \\n3\"), Document(metadata={}, page_content='3 \\n \\n1.3 PROJECT METHODOLOGY \\n \\nPreparation Phase: \\n1. Familiarization with Autopsy: Gain proficiency in Autopsy by \\nthoroughly studying its documentation, tutorials, and user guides to \\nunderstand its functionalities and capabilities.'), Document(metadata={}, page_content=\"understand its functionalities and capabilities. \\n2. Selection of Test Cases: Identify real-world case studies and design \\ncontrolled experiments to evaluate Autopsy's performance in data \\nrecovery under varying conditions. \\nData Acquisition and Preservation:\"), Document(metadata={}, page_content='Data Acquisition and Preservation: \\n1. Acquisition of Digital Evidence: Collect hard drives or disk images \\nfrom criminal investigations, ensuring adherence to proper chain of \\ncustody protocols to maintain evidentiary integrity.'), Document(metadata={}, page_content='2. Preservation of Evidence: Create forensic copies of the acquired data to \\nprevent any alteration or corruption, thereby preserving the integrity of \\nthe original evidence. \\nData Recovery and Analysis: \\n1. Utilization of Autopsy: Employ Autopsy to conduct comprehensive'), Document(metadata={}, page_content=\"analysis and recovery of deleted data from the acquired hard drives or \\ndisk images. \\n2. File Carving and Keyword Search: Utilize Autopsy's file carving and \\nkeyword search functionalities to identify and recover relevant files \\ncrucial to the investigation.\"), Document(metadata={}, page_content=\"crucial to the investigation. \\n3. Timeline Analysis: Leverage Autopsy to establish accurate timelines and \\nsequences of events based on the recovered data, aiding in reconstructing \\nthe digital footprint of the suspect's activities. \\nValidation and Interpretation:\"), Document(metadata={}, page_content='Validation and Interpretation: \\n1. Validation of Recovered Data: Verify the authenticity and integrity of \\nthe recovered data using robust validation techniques to ensure its \\nadmissibility as evidence. \\n2. Interpretation of Findings: Analyse the recovered data to discern'), Document(metadata={}, page_content='patterns, connections, and potential evidence relevant to the criminal \\ninvestigations, providing valuable insights for further analysis. \\n4 \\n \\n1.4 SCOPE OF PROJECT \\n \\n1. Criminal Investigations: Digital forensics plays a critical role in'), Document(metadata={}, page_content='criminal investigations by analysing digital devices such as computers, \\nsmartphones, and storage media to gather evidence. This evidence can \\ninclude emails, text messages, internet history, and deleted files, which \\ncan help investigators reconstruct events, identify suspects, and establish'), Document(metadata={}, page_content='motives. For example, in cases of cybercrimes, digital forensics experts \\nanalyse network logs and digital communications to track down \\nperpetrators. \\n2. Corporate Investigations: In the corporate world, digital forensics is'), Document(metadata={}, page_content='used to investigate incidents such as data breaches, intellectual property \\ntheft, and employee misconduct. Digital forensics experts analyse \\ncorporate networks, servers, and employee devices to identify security \\nbreaches, unauthorized access, and data exfiltration. This information is'), Document(metadata={}, page_content='crucial for organizations to strengthen their cybersecurity measures and \\nprevent future incidents. \\n3. Civil Litigation: Digital forensics is frequently used in civil litigation \\ncases such as intellectual property disputes, employment lawsuits, and'), Document(metadata={}, page_content='contract disputes. Digital evidence, including emails, documents, and \\nelectronic communications, can be analysed to support legal claims or \\ndefences. For example, in cases involving intellectual property \\ninfringement, digital forensics can uncover evidence of copyright or \\npatent violations.'), Document(metadata={}, page_content='patent violations. \\n4. Law Enforcement: Law enforcement agencies use digital forensics to \\ninvestigate a wide range of crimes, including fraud, theft, and terrorism. \\nDigital evidence obtained from computers, mobile phones, and other'), Document(metadata={}, page_content='digital devices can provide crucial leads and help solve cases. For \\ninstance, in cases of financial fraud, digital forensics experts may analyse \\nbanking records, online transactions, and communication logs to trace the \\nflow of funds and identify perpetrators.'), Document(metadata={}, page_content='flow of funds and identify perpetrators. \\n5. Counterterrorism and National Security: Digital forensics is essential \\nfor counterterrorism and national security efforts, as it allows authorities \\nto monitor and track terrorist activities online. Digital forensics experts'), Document(metadata={}, page_content='analyse communication channels, social media platforms, and encrypted \\nmessages to identify potential threats and disrupt terrorist networks. \\n5 \\n \\nAdditionally, digital evidence obtained from seized electronic devices can \\nprovide valuable intelligence for preventing future attacks.'), Document(metadata={}, page_content='1.5 LIMITATIONS \\n \\n1. Scope Constraints: The project may have limitations in terms of its \\nscope, particularly regarding the range of controlled experiments and \\nreal-world case studies that can be included. Due to time and resource'), Document(metadata={}, page_content='constraints, it may not be possible to cover every possible scenario or \\ntype of criminal activity, which could impact the comprehensiveness of \\nthe findings. \\n2. Access to Data: Obtaining access to real-world digital evidence from'), Document(metadata={}, page_content='criminal investigations may pose challenges due to legal, ethical, and \\nprivacy considerations. Access to sensitive data may be restricted, \\nlimiting the scope of the project and potentially affecting the diversity of \\ncase studies and experiments.'), Document(metadata={}, page_content=\"case studies and experiments. \\n3. Tool-Specific Focus: The project's focus on evaluating Autopsy's \\nperformance may limit the generalizability of the findings to other digital \\nforensics tools. While Autopsy is a widely used tool, its capabilities and\"), Document(metadata={}, page_content=\"limitations may differ from other commercial or proprietary tools, thus \\nrestricting the broader applicability of the project's conclusions. \\n4. Resource Limitations: The project may face constraints in terms of \\naccess to specialized equipment, software licenses, and expertise in\"), Document(metadata={}, page_content='digital forensics. Limited resources could impact the depth and rigor of \\nthe experiments and analyses conducted, potentially affecting the \\nreliability and validity of the results. \\n5. Technical Challenges: Digital forensics investigations often encounter'), Document(metadata={}, page_content='technical challenges such as data encryption, file fragmentation, and anti-\\nforensic techniques employed by perpetrators. The project may encounter \\ndifficulties in overcoming these challenges, which could affect the \\neffectiveness of data recovery efforts and the overall outcomes of the \\nproject.'), Document(metadata={}, page_content=\"project. \\n6. External Factors: External factors such as changes in technology, legal \\nregulations, and cybersecurity threats may impact the relevance and \\ntimeliness of the project's findings. The rapidly evolving nature of digital \\n6\"), Document(metadata={}, page_content=\"6 \\n \\nforensics and the digital landscape may necessitate ongoing updates and \\nadjustments to the project's methodology and conclusions. \\n7. Ethical Considerations: The project must adhere to ethical guidelines \\nand principles, particularly regarding the handling and analysis of\"), Document(metadata={}, page_content='sensitive digital evidence. Ethical considerations related to privacy, \\nconfidentiality, and data protection may impose limitations on the types \\nof experiments conducted and the dissemination of findings. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n7 \\n \\n \\n \\n \\n \\n \\nChapter 2'), Document(metadata={}, page_content='7 \\n \\n \\n \\n \\n \\n \\nChapter 2 \\nWhat is Digital Forensics? \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n8 \\n \\n2.1 DIGITAL FORENSICS \\n \\nDigital forensics is a multidisciplinary field of forensic science that involves the \\nidentification, preservation, extraction, analysis, and interpretation of digital'), Document(metadata={}, page_content='evidence from electronic devices and digital media. It encompasses a wide \\nrange of techniques, methodologies, and tools to investigate various types of \\ncybercrimes, security incidents, and legal disputes involving digital information.'), Document(metadata={}, page_content='At its core, digital forensics aims to uncover and interpret digital artifacts stored \\non computers, mobile devices, storage media, and networks to reconstruct \\nevents, establish timelines, identify suspects, and support legal proceedings.'), Document(metadata={}, page_content='These artifacts can include files, emails, documents, images, videos, internet \\nbrowsing history, chat logs, metadata, and system logs, among others. \\n \\nDigital forensics investigations typically follow a systematic approach, starting'), Document(metadata={}, page_content='with the identification and preservation of digital evidence to prevent tampering \\nor alteration. This involves the use of specialized tools and techniques to create \\nforensic copies or images of storage media, ensuring that the original evidence'), Document(metadata={}, page_content='remains intact and admissible in court. Chain of custody protocols are followed \\nto maintain the integrity and authenticity of the evidence throughout the \\ninvestigation process. \\n \\nOnce the digital evidence is acquired and preserved, forensic analysts employ'), Document(metadata={}, page_content='various methods to analyze and interpret the data. This may include manual \\nexamination of files and directories, as well as the use of automated tools and \\nsoftware applications designed specifically for digital forensics. Common'), Document(metadata={}, page_content='analysis techniques include file carving, keyword searching, metadata analysis, \\ntimeline reconstruction, and data visualization. \\n \\nDigital forensics investigations often involve collaboration between forensic \\nanalysts, law enforcement agencies, legal professionals, cybersecurity experts,'), Document(metadata={}, page_content='and other stakeholders. Analysts must adhere to legal and ethical guidelines \\nwhen conducting investigations, ensuring that privacy rights are respected and \\nsensitive information is handled appropriately. This includes obtaining proper \\n9'), Document(metadata={}, page_content='9 \\n \\nauthorization for accessing and analyzing digital evidence, as well as protecting \\nthe confidentiality of individuals involved in the investigation. \\n \\nOne of the key challenges in digital forensics is the rapidly evolving nature of'), Document(metadata={}, page_content='technology and the increasing complexity of digital systems and networks. \\nInvestigators must stay abreast of emerging technologies, encryption \\ntechniques, anti-forensic tools, and cybersecurity threats to effectively conduct \\ninvestigations and mitigate risks. Continuous training, research, and'), Document(metadata={}, page_content='collaboration within the digital forensics community are essential for staying \\nahead of evolving threats and advancing the field. \\n \\nOverall, digital forensics plays a crucial role in modern-day investigations, \\ncybersecurity efforts, and legal proceedings. By leveraging advanced techniques'), Document(metadata={}, page_content='and methodologies, digital forensics enables investigators to uncover valuable \\nevidence, identify perpetrators, and hold individuals accountable for \\ncybercrimes and other illicit activities in the digital realm. \\n \\n2.2 Types of Digital Forensics'), Document(metadata={}, page_content='2.2 Types of Digital Forensics \\n \\n1. Computer Forensics: Computer forensics focuses on the examination of \\ndigital evidence stored on computers and related devices such as hard \\ndrives, solid-state drives (SSDs), and memory cards. It involves the'), Document(metadata={}, page_content='collection and analysis of data to uncover information related to criminal \\nactivities, unauthorized access, data breaches, and other security \\nincidents. Computer forensics techniques include disk imaging, file \\ncarving, keyword searching, and timeline analysis.'), Document(metadata={}, page_content='2. Mobile Device Forensics: Mobile device forensics deals with the \\ninvestigation of digital evidence stored on mobile phones, smartphones, \\ntablets, and other portable devices. It includes the extraction and analysis \\nof data from device memory, SIM cards, and external storage media to'), Document(metadata={}, page_content='recover deleted messages, call logs, contacts, photos, and application \\ndata. Mobile device forensics techniques may involve physical extraction, \\nlogical extraction, and file system analysis. \\n10 \\n \\n3. Network Forensics: Network forensics focuses on the monitoring and'), Document(metadata={}, page_content='analysis of network traffic to detect and investigate security incidents, \\nintrusions, and cyberattacks. It involves the collection and analysis of \\nnetwork packets, logs, and metadata to identify suspicious activities, \\nunauthorized access, and data exfiltration. Network forensics techniques'), Document(metadata={}, page_content='include packet capture, traffic analysis, intrusion detection, and log \\nanalysis. \\n4. Memory Forensics: Memory forensics involves the analysis of volatile \\nmemory (RAM) to extract and analyse digital evidence from running \\nprocesses, system services, and active network connections. It allows'), Document(metadata={}, page_content='investigators to uncover malware, rootkits, and other malicious artifacts \\nthat may be concealed in memory. Memory forensics techniques include \\nmemory dumping, process analysis, and artifact extraction. \\n5. Forensic Data Analysis: Forensic data analysis focuses on the'), Document(metadata={}, page_content='examination and interpretation of large datasets to uncover patterns, \\ntrends, and anomalies related to criminal activities, financial fraud, and \\nother illicit behaviours. It involves the use of statistical analysis, data \\nmining, and visualization techniques to identify relevant information and'), Document(metadata={}, page_content='support investigative efforts. \\nThese types of digital forensics are interconnected and may overlap in practice, \\ndepending on the nature of the investigation and the type of digital evidence \\ninvolved. Each type of digital forensics requires specialized skills, tools, and'), Document(metadata={}, page_content='methodologies to effectively collect, analyse, and interpret digital evidence for \\ninvestigative purposes. \\n \\n2.3 AUTOPSY SOFTWARE \\n \\nAutopsy software falls primarily into the category of computer forensics tools. \\nComputer forensics tools are specifically designed to aid in the investigation'), Document(metadata={}, page_content='and analysis of digital evidence stored on computers and related devices. They \\nprovide functionalities for acquiring, preserving, and analysing data from \\nstorage media such as hard drives, solid-state drives (SSDs), and memory cards.'), Document(metadata={}, page_content='These tools often include features such as disk imaging, file carving, keyword \\nsearching, metadata analysis, and timeline reconstruction, which are essential \\nfor conducting forensic examinations of digital evidence. \\n11'), Document(metadata={}, page_content='11 \\n \\nAutopsy, being an open-source digital forensics platform, is designed to serve \\nthe needs of computer forensics investigators by providing a comprehensive \\nsuite of tools and capabilities for analysing digital evidence. It allows'), Document(metadata={}, page_content=\"investigators to examine file systems, recover deleted files, analyse internet \\nhistory, and extract valuable information from various types of digital media. \\nAutopsy's versatility and extensive feature set make it well-suited for\"), Document(metadata={}, page_content='conducting in-depth forensic examinations of computers and related devices, \\nthereby aiding in criminal investigations, incident response, and cybersecurity \\nefforts. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n12 \\n \\n \\n \\n \\n \\n \\nChapter 3 \\nImplementation \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n13'), Document(metadata={}, page_content='Implementation \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n13 \\n \\n3.1 FAMILIARIZATION WITH AUTOPSY \\n \\nDownload and install Autopsy by following the instructions on website \\nhttps://www.autopsy.com/download/ \\n \\n \\n14 \\n \\n3.2 DATA ACQUISITION AND PRESERVATION \\n \\n1. Identification of Digital Evidence:'), Document(metadata={}, page_content='1. Identification of Digital Evidence: \\n   Digital forensic analysts identify potential sources of digital evidence relevant \\nto the investigation, including electronic devices such as computers, mobile \\nphones, and storage media like hard drives or USB drives.'), Document(metadata={}, page_content='2. Legal Authorization and Collection: \\n   Once potential evidence sources are identified, legal authorization, such as \\nwarrants, is obtained to collect the evidence. This involves seizing electronic \\ndevices and storage media from crime scenes, suspects, or third-party entities.'), Document(metadata={}, page_content=\"3. Chain of Custody Documentation: \\n   Chain of custody documentation is maintained throughout the collection \\nprocess, documenting each step of the evidence's custody, transfer, and storage. \\nThis documentation includes details such as who collected the evidence, where\"), Document(metadata={}, page_content='it was stored, and any individuals who had access to it. \\n \\n4. Preservation Measures \\n   Preservation measures are taken to prevent alteration, tampering, or corruption \\nof the original data. Forensic copies or images of the acquired devices or storage'), Document(metadata={}, page_content='media are created using specialized imaging tools. These forensic copies are \\nexact replicas of the original data and are used for analysis while preserving the \\nintegrity of the original evidence. \\n \\n5. Forensic Imaging Process'), Document(metadata={}, page_content='5. Forensic Imaging Process \\n   Forensic imaging involves creating a bit-by-bit copy of the entire storage \\nmedia, including allocated and unallocated space, file system metadata, and \\ndeleted data. Verified and validated forensic imaging tools and techniques are'), Document(metadata={}, page_content='used to ensure the accuracy and reliability of the forensic copies. \\n \\n15 \\n \\n6. Storage and Security \\n   Once created, forensic copies are securely stored in a controlled environment \\nwith restricted access. Strict security measures, including encryption and access'), Document(metadata={}, page_content='controls, are implemented to prevent unauthorized access, tampering, or loss of \\nthe evidence. Backup copies may also be created to protect against data loss or \\ncorruption. \\n \\n7. Documentation and Reporting \\n   Detailed documentation is maintained throughout the acquisition and'), Document(metadata={}, page_content='preservation process, including chain of custody logs, imaging reports, and \\nevidence seizure records. This documentation provides a comprehensive record \\nof the handling and storage of digital evidence and serves as crucial'), Document(metadata={}, page_content='documentation for legal proceedings. A comprehensive report summarizing the \\nacquisition and preservation process is prepared for inclusion in the case file. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n16 \\n \\n3.3 DATA RECOVERY \\n \\nUtilization of Autopsy:'), Document(metadata={}, page_content='3.3 DATA RECOVERY \\n \\nUtilization of Autopsy: \\nAfter creating RAW backup of evidence, plug your in your evidence copy \\n \\n \\nNow create new case \\n \\n17 \\n \\nFill in required information \\n \\n \\n \\nSelect copy of evidence  \\n(IMPORTANT !! DO NOT USE EVIDENCE DIRECTLY)'), Document(metadata={}, page_content='(IMPORTANT !! DO NOT USE EVIDENCE DIRECTLY) \\n \\n \\nSelect which type of file you want to extract \\n18 \\n \\n \\n \\n \\nLet it scan through your copy of evidence \\n \\n \\n \\n \\nAfter scan your screen should look like this \\n19 \\n \\n \\n \\nNow you can look through the deleted files by selecting “Deleted files” from'), Document(metadata={}, page_content='navigation panel. \\n \\n \\n \\nNot just photos but videos, previously connected WiFi, deleted/installed \\nprograms, saved html, bookmarks, history, text files, code in any language and \\nmany more things can be extracted from evidence. \\n20 \\n \\n \\n \\n \\nIn case some file is not running in preview tab,'), Document(metadata={}, page_content='You can extract them for playback in another application \\n \\n21 \\n \\n \\n \\nFor example, this video file was not playing in preview tab, so we extracted it \\ninto “Export” folder inside the case folder and then playback in other video \\nplayer like VLC.'), Document(metadata={}, page_content='player like VLC. \\n \\nOf course just recovering files is not enough in proving someone guilty, \\nfor example, \\n \\n1. Possession of porno, under section 292 of IPC, will put you behind bars \\nfor 2 years and a fine extending to INR 2000 on first conviction and up to'), Document(metadata={}, page_content='5 years and INR 5000 on subsequent conviction. \\n2. Sale/distribution of porno, under section 67 of IT Act, will put you behind \\nbars for 5 years and a fine extending to INR 10,00,000 on first conviction \\nand up to 7 years and INR 10,00,000 on subsequent conviction.'), Document(metadata={}, page_content='That is why we need to look at the timeline since it can show when and where \\nthe file was created ,when it was accessed or modified, this information is \\nimportant in order to determine whether the accused just downloaded porno \\nfrom internet or it was created locally. \\n \\n22 \\n \\n3.4 ANALYSIS'), Document(metadata={}, page_content='22 \\n \\n3.4 ANALYSIS \\n \\nUtilization of Timeline: \\n1. Open Autopsy: \\n   Launch the Autopsy software on your computer. \\n \\n2. Create or Open a Case: \\n   Create a new case or open an existing one where you have already added a \\ndata source (such as a disk image or file system).'), Document(metadata={}, page_content='3. Navigate to the Timeline View: \\n   Once inside the case, locate and click on the \"Timeline\" tab or view. This \\nshould be located alongside other tabs like \"Summary,\" \"File Analysis,\" etc. \\n \\n4. Select the Data Source:'), Document(metadata={}, page_content='4. Select the Data Source: \\n   If you have multiple data sources added to the case, select the one you want to \\nanalyse using the timeline. This could be a disk image or file system. \\n \\n5. Configure Timeline Options (Optional):'), Document(metadata={}, page_content='5. Configure Timeline Options (Optional): \\n   Autopsy provides options to configure the timeline display based on your \\npreferences. You can adjust settings such as the time range, granularity, and \\nfilters to refine the data displayed on the timeline. \\n \\n6. View Timeline Events:'), Document(metadata={}, page_content='6. View Timeline Events: \\n   Autopsy will display a chronological timeline of events based on the data \\nsource you selected. These events may include file creation, modification, \\naccess times, and other relevant activities extracted from the digital evidence. \\n \\n7. Analyse Timeline Events: \\n23'), Document(metadata={}, page_content='7. Analyse Timeline Events: \\n23 \\n \\n   Review the timeline events to identify patterns, anomalies, or suspicious \\nactivities. You can navigate through the timeline using various controls and \\nfilters to focus on specific time frames or types of events. \\n8. Interpret Timeline Data:'), Document(metadata={}, page_content='8. Interpret Timeline Data: \\n   Analyse the timeline data to reconstruct the sequence of events, establish \\ntimelines, and identify potential leads or evidence relevant to the investigation. \\nPay attention to correlations between timeline events and other forensic artifacts'), Document(metadata={}, page_content='to build a comprehensive understanding of the case. \\n9. Document Findings: \\n   Document any significant findings or observations from the timeline analysis. \\nThis documentation is crucial for reporting and presenting findings in legal \\nproceedings or investigative reports. \\n10. Further Analysis:'), Document(metadata={}, page_content='10. Further Analysis: \\n    Use the insights gained from the timeline analysis to guide further \\nexamination of digital evidence using other features and tools available in \\nAutopsy, such as keyword search, file analysis, and metadata examination.'), Document(metadata={}, page_content='By following these steps, you can effectively utilize the timeline feature in \\nAutopsy to analyse digital evidence and reconstruct timelines of events relevant \\nto your investigation. \\n \\n \\n \\n24 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n25 \\n \\n \\n \\n \\n \\n \\nChapter 4 \\nResult and Conclusion \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n26'), Document(metadata={}, page_content='26 \\n \\n4.1 Validation and Interpretation: \\n \\nValidation of Recovered Data: \\nEnsuring the authenticity and integrity of the recovered data is paramount in \\ndigital forensics to uphold its admissibility as evidence in legal proceedings.'), Document(metadata={}, page_content='Robust validation techniques are employed to meticulously verify the accuracy \\nand reliability of the recovered data. This process involves comparing the \\nrecovered data against known sources of truth, such as original files or system'), Document(metadata={}, page_content='backups, to identify any discrepancies or inconsistencies. Additionally, \\ncryptographic hashing algorithms may be used to generate unique hash values \\nfor the recovered data, allowing for verification of data integrity. By'), Document(metadata={}, page_content='meticulously validating the recovered data, forensic analysts can establish \\nconfidence in its reliability and suitability for use as evidence in criminal \\ninvestigations. \\n \\nInterpretation of Findings: \\nOnce the recovered data has been validated, forensic analysts embark on the'), Document(metadata={}, page_content='critical task of interpreting the findings to extract valuable insights relevant to \\nthe criminal investigation. This involves analysing the recovered data to discern \\npatterns, connections, and potential evidence that may shed light on the'), Document(metadata={}, page_content='circumstances surrounding the case. Analysts meticulously examine digital \\nartifacts, such as files, emails, chat logs, and system logs, to identify suspicious \\nactivities, timelines of events, and relationships between individuals or entities'), Document(metadata={}, page_content='involved. By drawing upon their expertise in digital forensics and investigative \\ntechniques, analysts provide valuable insights that can inform further analysis, \\ncorroborate witness statements, and support the development of investigative'), Document(metadata={}, page_content='leads. The interpretation of findings plays a pivotal role in uncovering crucial \\nevidence and building a compelling case narrative, ultimately contributing to \\nthe successful resolution of criminal investigations. \\n \\n \\n \\n \\n \\n27 \\n \\n4.2 Documentation and Reporting: \\n \\nDocumentation of Procedures:'), Document(metadata={}, page_content='Documentation of Procedures: \\nThorough documentation of the data recovery process is essential in digital \\nforensics to ensure transparency, repeatability, and accountability. Forensic \\nanalysts meticulously document every step taken, tool utilized, and observation'), Document(metadata={}, page_content='made during the investigation. This includes detailed records of the data \\nacquisition process, forensic imaging procedures, analysis techniques employed, \\nand any deviations from standard protocols. Documentation also encompasses'), Document(metadata={}, page_content='chain of custody logs, which track the custody, transfer, and storage of digital \\nevidence throughout the investigation. By maintaining comprehensive \\ndocumentation of procedures, forensic analysts provide a clear record of their'), Document(metadata={}, page_content='actions, facilitating peer review, quality assurance, and legal scrutiny of the \\ninvestigative process. \\n \\nReporting of Results: \\nCompiling a comprehensive report is a crucial aspect of the digital forensic \\ninvestigation process, providing stakeholders with valuable insights into'), Document(metadata={}, page_content=\"Autopsy's effectiveness in recovering deleted data and the overall outcomes of \\nthe investigation. The report highlights key findings, challenges encountered, \\nand recommendations for future investigations. It includes a detailed analysis of\"), Document(metadata={}, page_content=\"Autopsy's performance, including its ability to recover various types of deleted \\ndata, the accuracy of recovered data, and any limitations or shortcomings \\nobserved during the investigation. Additionally, the report discusses the\"), Document(metadata={}, page_content='methodologies employed, the significance of recovered evidence to the case, \\nand any potential implications for legal proceedings. By presenting findings in a \\nclear, concise, and well-organized manner, the report serves as a critical tool for'), Document(metadata={}, page_content=\"informing decision-making, guiding further analysis, and supporting the \\nresolution of criminal investigations. \\n \\n \\n \\n \\n \\n28 \\n \\n4.3 Analysis and Conclusion: \\n \\nAnalysis of Results: \\nThe analysis of data recovery results is a critical step in assessing Autopsy's\"), Document(metadata={}, page_content=\"performance and its implications for digital forensics. This analysis involves \\ncarefully examining the recovered data, considering Autopsy's performance in \\nterms of data recovery accuracy, efficiency, and reliability. Forensic analysts\"), Document(metadata={}, page_content=\"evaluate Autopsy's strengths and limitations, including its ability to handle \\nvarious file systems, recover different types of deleted data, and overcome \\ntechnical challenges such as data encryption or file fragmentation. By\"), Document(metadata={}, page_content=\"conducting a thorough analysis, analysts gain a nuanced understanding of \\nAutopsy's capabilities and its potential impact on digital forensic investigations. \\n \\nConclusion and Recommendations: \\nDrawing upon the analysis, the project draws conclusive insights and offers\"), Document(metadata={}, page_content=\"actionable recommendations for enhancing Autopsy's efficacy in recovering \\ndeleted data from criminal hard drives. These recommendations may include \\nsuggestions for optimizing Autopsy's algorithms, improving its user interface,\"), Document(metadata={}, page_content='enhancing its compatibility with different file systems and storage media, and \\naddressing any identified limitations or shortcomings. Additionally, the project \\nmay propose avenues for further research and development in the field of digital'), Document(metadata={}, page_content='forensics, such as exploring new techniques for data recovery, integrating \\nartificial intelligence or machine learning algorithms, or advancing forensic \\nanalysis methodologies. By providing actionable recommendations, the project'), Document(metadata={}, page_content=\"aims to contribute to the continuous improvement of Autopsy and the broader \\nfield of digital forensics, ultimately enhancing investigators' ability to recover \\nand analyse digital evidence in criminal investigations. \\n \\n \\n \\n \\n \\n \\n29 \\n \\nReferences\"), Document(metadata={}, page_content='29 \\n \\nReferences \\n \\n[1] Carrier, B. (2005). File System Forensic Analysis. Addison-Wesley \\nProfessional. Available at: https://www.pearson.com/us/higher-\\neducation/program/Carrier-File-System-Forensic-Analysis/PGM335579.html'), Document(metadata={}, page_content='[2] Casey, E. (2011). Digital Evidence and Computer Crime: Forensic Science, \\nComputers and the Internet. Academic Press. Available at: \\nhttps://www.elsevier.com/books/digital-evidence-and-computer-\\ncrime/casey/978-0-12-374268-1'), Document(metadata={}, page_content='crime/casey/978-0-12-374268-1 \\n[3] Nelson, B., Phillips, A., & Steuart, C. (2009). Guide to Computer Forensics \\nand Investigations. Cengage Learning. Available at: \\nhttps://www.cengage.com/c/guide-to-computer-forensics-and-investigations-5e-\\nnelson'), Document(metadata={}, page_content='nelson \\n[4] Sammons, J. (2012). The Basics of Digital Forensics: The Primer for Getting \\nStarted in Digital Forensics. Elsevier Science. Available at: \\nhttps://www.elsevier.com/books/the-basics-of-digital-forensics/sammons/978-1-\\n59749-661-7'), Document(metadata={}, page_content='59749-661-7 \\n[5] SANS Institute. (2020). SANS Digital Forensics and Incident Response. \\nRetrieved from: https://www.sans.org/')]\n","output_type":"stream"}]},{"cell_type":"code","source":"from llama_cpp import Llama\nimport time\n# Path to your downloaded and quantized .gguf model\nmodel_path = \"/kaggle/working/bge-small-en-v1.5-f16.gguf\"\n\n# Load the model\nmodel2 = Llama(model_path=model_path, embedding=True, verbose=False)\n\n# Example of document embedding extraction (pseudo-code):\nstart = time.time()\n\ndocument_embeddings = []\n# Generate Embeddings for every single document in documents and append it into document_embeddings\nfor document in documents:\n    embeddings = model2.create_embedding([document.page_content])\n    document_embeddings.append({\n        \"content\": document.page_content,\n        \"embedding\": embeddings[\"data\"][0][\"embedding\"]\n    })\n\nend = time.time()\nall_text = [item.page_content for item in documents]\nchar_per_sec = len(''.join(all_text))/ (end-start)\nprint(f\"TIME: {end-start:.2f} seconds / {char_per_sec:,.2f} chars/second\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T17:24:55.973662Z","iopub.execute_input":"2024-09-16T17:24:55.974601Z","iopub.status.idle":"2024-09-16T17:25:02.483078Z","shell.execute_reply.started":"2024-09-16T17:24:55.974550Z","shell.execute_reply":"2024-09-16T17:25:02.481889Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"TIME: 6.40 seconds / 5,369.43 chars/second\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(document_embeddings))\nprint(document_embeddings[0])","metadata":{"execution":{"iopub.status.busy":"2024-09-16T17:25:02.484505Z","iopub.execute_input":"2024-09-16T17:25:02.484913Z","iopub.status.idle":"2024-09-16T17:25:02.491558Z","shell.execute_reply.started":"2024-09-16T17:25:02.484872Z","shell.execute_reply":"2024-09-16T17:25:02.490078Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"134\n{'content': 'DIGITAL FORENSICS \\nA project submitted in partial fulfilment of the \\nRequirements of the award of the degree of \\nBachelor of Technology \\nIn \\nCOMPUTER SCIENCE AND ENGINEERING \\n \\nSubmitted by: Mohit Singh and Ayush Dwibedy \\nRoll number: 12211003 and 12211001 \\nSupervised by: Dr. Bhupesh Singh Bhati', 'embedding': [-0.5953239798545837, 0.4383507966995239, -0.21312794089317322, -0.6411929130554199, 0.306092232465744, -0.43380069732666016, 0.04449070245027542, 0.0903160348534584, 0.2038203328847885, -0.16241469979286194, 0.3360426425933838, -0.12287573516368866, -0.014609724283218384, -0.22079306840896606, 0.2801952064037323, 0.3578204810619354, 0.24406686425209045, 0.4119477868080139, 0.4558127522468567, 0.21492066979408264, 0.6882129907608032, -0.10202240943908691, -0.2798982858657837, -0.4018635153770447, -0.5612760782241821, 0.1056562066078186, 0.011548779904842377, -0.9722949266433716, -0.3901754915714264, -1.194531798362732, -0.327472060918808, -0.19135957956314087, 0.5870811939239502, 0.01492270827293396, -0.029339993372559547, -0.4783381521701813, -0.22386954724788666, 0.2117786556482315, -0.01970437541604042, -0.28699401021003723, -0.3247568607330322, -0.07516005635261536, 0.6844486594200134, -0.3454517424106598, -0.057768985629081726, -0.12116371840238571, -0.698994517326355, 0.10897256433963776, -0.2037827968597412, -0.4040848910808563, 0.25253280997276306, -0.599621593952179, 0.04928917437791824, 0.2930576205253601, -0.2972922921180725, -0.5686156749725342, 0.6860049962997437, 0.44498196244239807, 0.2600073218345642, -0.1189470887184143, 0.31719839572906494, 0.2995644211769104, -1.052797555923462, 0.33497053384780884, 0.1643100380897522, 0.4575163722038269, 0.2382657527923584, -0.6538133025169373, 0.521973192691803, 0.3151205778121948, -0.23467853665351868, 0.08223504573106766, 0.3240216374397278, 0.29629412293434143, 0.2225889265537262, -0.030412033200263977, 0.2432827651500702, -0.11295341700315475, -0.10324271768331528, -0.4054202139377594, -0.22822046279907227, 0.2641492784023285, 0.48985493183135986, 0.1189647763967514, -0.6176990866661072, -0.04092833399772644, -0.13324274122714996, -0.13339847326278687, -0.11371967196464539, 0.03746192157268524, 0.4195424020290375, 0.10685339570045471, -0.20345140993595123, -0.000731833279132843, -0.5072299242019653, -0.272563099861145, 0.16904421150684357, 0.08168211579322815, 0.18917879462242126, 3.6734325885772705, -0.568663477897644, -0.5465843081474304, -0.11916980147361755, -0.4902944266796112, 0.30832910537719727, -0.2862117290496826, 0.0005545653402805328, -0.8255084753036499, -0.43431758880615234, -0.18534782528877258, 0.36032724380493164, 0.43793272972106934, 0.38895952701568604, 0.1308293342590332, 0.4940434992313385, 0.39816808700561523, -0.30407044291496277, 0.4577487111091614, -0.23861773312091827, -0.06413717567920685, -0.059040918946266174, 0.4040650427341461, 0.052835460752248764, -0.48427900671958923, 0.11536172777414322, -0.28670692443847656, -0.03742116689682007, 1.1108901500701904, 0.24334308505058289, 0.6525518298149109, -0.2745552659034729, -0.6237189769744873, -0.2845146358013153, 0.07662920653820038, 0.18038734793663025, -0.029673263430595398, 0.16554272174835205, 0.10017479956150055, -0.44634824991226196, -0.24335823953151703, -0.10859383642673492, 0.010915756225585938, 0.264019638299942, 0.2255069613456726, -0.6516032814979553, 0.6141050457954407, -0.17519335448741913, 0.3612479865550995, -0.24949313700199127, -0.5063300132751465, 0.33123883605003357, 0.037672240287065506, -0.4649580717086792, -0.28024232387542725, 0.30251988768577576, 0.12507587671279907, 0.05805234611034393, 0.13665521144866943, -0.457252562046051, 0.1331728994846344, 0.25415530800819397, -0.7321619391441345, 0.0036536380648612976, 1.8079097270965576, 0.1870494782924652, -0.7773588299751282, 0.1878758668899536, 0.23243600130081177, 0.24414128065109253, -0.6444963216781616, 0.26768362522125244, -0.16234835982322693, 0.01865287870168686, 0.15252085030078888, -0.7143433690071106, -0.14524662494659424, -0.04527940973639488, -0.06992345303297043, -0.47498300671577454, 0.17443051934242249, -0.03290349245071411, -0.21491439640522003, -0.34414374828338623, 0.46979087591171265, 0.2863234281539917, -0.4859495460987091, -0.12069923430681229, 0.23626351356506348, 0.465044230222702, 0.38597530126571655, -0.6881090998649597, 0.0030943825840950012, -0.09918587654829025, 0.07586430013179779, 0.10539637506008148, 0.39623433351516724, -0.12230108678340912, -0.3234214782714844, -0.47846829891204834, 0.19287410378456116, 0.5043376088142395, 0.20106634497642517, -0.45242398977279663, 0.5535343289375305, 0.5779105424880981, -0.16874727606773376, -0.026958290487527847, -0.27508577704429626, -0.10861791670322418, 0.9800856113433838, -0.07397127151489258, -0.41787827014923096, 0.28418272733688354, -0.1010514348745346, -0.17252600193023682, -0.08510424196720123, -0.09497477114200592, 0.6506658792495728, 0.23303692042827606, 0.32146722078323364, -0.6380184292793274, -0.25800132751464844, -0.14660266041755676, -2.7977709770202637, -0.35010430216789246, -0.33126938343048096, -0.012369334697723389, 0.21269965171813965, -0.17360931634902954, 0.38714784383773804, -0.07072756439447403, 0.28743976354599, 0.5111424922943115, 0.8231647610664368, 0.07650050520896912, -0.05977104976773262, -0.23604077100753784, 0.20757229626178741, 0.040611907839775085, 0.7544558644294739, -0.18031345307826996, 0.1034906804561615, -0.4008059501647949, -0.39423447847366333, 0.5188497304916382, -0.17900043725967407, -0.14223933219909668, 0.5317685604095459, 0.016210302710533142, 1.3523768186569214, -0.31108033657073975, -0.048153288662433624, -0.03836468234658241, -0.23854514956474304, 0.42035239934921265, -0.12926700711250305, -1.0538512468338013, 0.2588704228401184, -0.15238302946090698, -0.45259010791778564, 0.29540911316871643, -0.07372301816940308, -0.12123379856348038, 0.015094086527824402, 0.05651581287384033, 0.5823545455932617, -0.149972602725029, 0.07876760512590408, -0.5621932744979858, -0.45305168628692627, -0.6640221476554871, -0.26927727460861206, 0.3771249055862427, -0.028162755072116852, 0.24198803305625916, 0.010046213865280151, 0.2689880132675171, -0.4875693917274475, 0.06745491921901703, -0.3011729121208191, -0.059170693159103394, -0.21626539528369904, -0.2907599210739136, -0.11642000824213028, -0.5391331911087036, -0.49323034286499023, -0.6188795566558838, 0.5280519723892212, -0.242224782705307, -0.041360415518283844, 0.2099086344242096, -0.5344922542572021, -0.16459985077381134, 0.4149615466594696, 0.7002229690551758, 0.3734440207481384, -0.6029937863349915, 0.18192905187606812, -0.0028788037598133087, 0.23546484112739563, -0.21295882761478424, 0.252289354801178, 0.22941285371780396, 0.31863516569137573, 0.431652307510376, 0.2488376349210739, 0.3941764235496521, 0.5386508703231812, 0.17169123888015747, 0.6494712829589844, 0.09946251660585403, -0.0577564537525177, 0.30367469787597656, 0.1556687355041504, -0.1903403252363205, -0.06748861819505692, 0.09173685312271118, 0.13797327876091003, 0.4505254030227661, -2.0663115978240967, 0.050494078546762466, -0.31080543994903564, 0.8102477788925171, -0.07542600482702255, -0.31101930141448975, 0.6491971015930176, 0.3230332136154175, 0.38635802268981934, 0.27725687623023987, -0.29827287793159485, 0.17303067445755005, 0.30807462334632874, -0.3254517614841461, 0.5181102752685547, -0.39096036553382874, 0.19138382375240326, -0.31294894218444824, -0.192857027053833, 0.08536010980606079, -0.15339498221874237, 0.3117086589336395, 1.3192042112350464, -0.16580115258693695, 0.3384377956390381, 0.16362300515174866, 0.006304267793893814, 0.13956567645072937, 0.06447659432888031, -0.4323063790798187, -0.03282081335783005, -0.6136438250541687, 0.6518053412437439, -0.25651639699935913, -0.660709023475647, 0.2961916923522949, -0.35172465443611145, 0.3913179636001587, -0.30363431572914124, 0.26009654998779297, 0.043716222047805786, -0.32239067554473877, -0.5816579461097717, -0.06013559177517891, 0.848671019077301, 0.6868327260017395, -0.10253103077411652, -0.7285661697387695, -0.14094120264053345, -0.07792189717292786, -0.29037150740623474, -0.0421251617372036, -0.1895066648721695, -0.3806752562522888, 0.18466296792030334, 0.9619942903518677, 0.09170591831207275, -0.07007381319999695, -0.5724940299987793, -0.37252846360206604, -0.11009340733289719, 0.45564740896224976, 0.2756892740726471, 0.6404344439506531, -0.0937143862247467]}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Weaviate schema creation (if not already created)\nclass_obj = {\n    \"class\": \"Pdf\",\n    \"vectorizer\": \"none\",\n}\n\n# Create the schema in Weaviate\nclient.schema.create_class(class_obj)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T17:25:02.493099Z","iopub.execute_input":"2024-09-16T17:25:02.493581Z","iopub.status.idle":"2024-09-16T17:25:02.615901Z","shell.execute_reply.started":"2024-09-16T17:25:02.493529Z","shell.execute_reply":"2024-09-16T17:25:02.613766Z"},"trusted":true},"execution_count":31,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnexpectedStatusCodeError\u001b[0m                 Traceback (most recent call last)","Cell \u001b[0;32mIn[31], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m class_obj \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPdf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvectorizer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m }\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Create the schema in Weaviate\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_obj\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/weaviate/schema/crud_schema.py:253\u001b[0m, in \u001b[0;36mSchema.create_class\u001b[0;34m(self, schema_class)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03mCreate a single class as part of the schema in Weaviate.\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m    If the 'schema_class' could not be validated against the standard format.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    252\u001b[0m loaded_schema_class \u001b[38;5;241m=\u001b[39m _get_dict_from_object(schema_class)\n\u001b[0;32m--> 253\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_class_with_primitives\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloaded_schema_class\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_complex_properties_from_class(loaded_schema_class)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/weaviate/schema/crud_schema.py:817\u001b[0m, in \u001b[0;36mSchema._create_class_with_primitives\u001b[0;34m(self, weaviate_class)\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsConnectionError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass may not have been created properly.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconn_err\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m--> 817\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedStatusCodeException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreate class\u001b[39m\u001b[38;5;124m\"\u001b[39m, response)\n","\u001b[0;31mUnexpectedStatusCodeError\u001b[0m: Create class! Unexpected status code: 422, with response body: {'error': [{'message': 'class name Pdf already exists'}]}."],"ename":"UnexpectedStatusCodeError","evalue":"Create class! Unexpected status code: 422, with response body: {'error': [{'message': 'class name Pdf already exists'}]}.","output_type":"error"}]},{"cell_type":"code","source":"# Insert embeddings into Weaviate\nclient.batch.configure(batch_size=100)\nwith client.batch as batch:\n    for doc in document_embeddings:\n        properties = {\n            \"content\": doc[\"content\"],\n        }\n        \n        batch.add_data_object(properties, \"Pdf\", vector=doc['embedding'])\n    ","metadata":{"execution":{"iopub.status.busy":"2024-09-16T17:31:26.448497Z","iopub.execute_input":"2024-09-16T17:31:26.449690Z","iopub.status.idle":"2024-09-16T17:31:27.094873Z","shell.execute_reply.started":"2024-09-16T17:31:26.449636Z","shell.execute_reply":"2024-09-16T17:31:27.093640Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"query =\"What is the main idea of this\"","metadata":{"execution":{"iopub.status.busy":"2024-09-16T17:31:30.203200Z","iopub.execute_input":"2024-09-16T17:31:30.203609Z","iopub.status.idle":"2024-09-16T17:31:30.208637Z","shell.execute_reply.started":"2024-09-16T17:31:30.203573Z","shell.execute_reply":"2024-09-16T17:31:30.207419Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# Generate Embeddings for every single document in documents and append it into document_embeddings\nquery_embeddings = model2.create_embedding(query)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T17:31:44.386856Z","iopub.execute_input":"2024-09-16T17:31:44.387318Z","iopub.status.idle":"2024-09-16T17:31:44.424433Z","shell.execute_reply.started":"2024-09-16T17:31:44.387277Z","shell.execute_reply":"2024-09-16T17:31:44.423166Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"query_vector=query_embeddings['data'][0][\"embedding\"]\nprint((query_vector))","metadata":{"execution":{"iopub.status.busy":"2024-09-16T17:31:47.274484Z","iopub.execute_input":"2024-09-16T17:31:47.274976Z","iopub.status.idle":"2024-09-16T17:31:47.281596Z","shell.execute_reply.started":"2024-09-16T17:31:47.274897Z","shell.execute_reply":"2024-09-16T17:31:47.280371Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"[-0.3989945948123932, 0.2232816070318222, -0.17050901055335999, -0.5948772430419922, -0.3338434398174286, 0.15947756171226501, 0.21101132035255432, 0.13173538446426392, 0.5502766966819763, 0.08833907544612885, 0.335594117641449, 0.1754680573940277, -0.12510782480239868, 0.27761679887771606, 0.008066884241998196, -0.10323846340179443, 0.07280999422073364, -0.377716988325119, -0.09725934267044067, 0.4027188718318939, 0.9518762230873108, 0.28120240569114685, -0.7239577174186707, 0.030685171484947205, -0.10306933522224426, 0.27936995029449463, 0.06543253362178802, 0.26560163497924805, 0.04149925708770752, -0.6514347195625305, 0.17708542943000793, -0.10122755169868469, 0.36209261417388916, 0.07186692953109741, -0.17927952110767365, 0.05112564563751221, -0.08540239930152893, 0.06492272764444351, -0.605852484703064, -0.01950012892484665, 0.455350399017334, -0.20247577130794525, -0.08594761788845062, 0.0750085711479187, 0.03862260282039642, -0.017768822610378265, -0.31826215982437134, 0.16521069407463074, 0.030734889209270477, -0.4950706660747528, -0.1340564340353012, -0.0930304229259491, -0.7887892723083496, -0.8508169651031494, -0.25626397132873535, 1.0441360473632812, 0.3943420648574829, -0.17703285813331604, 0.012380309402942657, 0.29638874530792236, 0.33888888359069824, 0.30827513337135315, -1.0822237730026245, 0.8161976933479309, 0.29822295904159546, 0.18343333899974823, 0.1930423378944397, 0.42836594581604004, 0.6890121102333069, 0.1486227959394455, -0.16512268781661987, 0.03356415033340454, 0.19539791345596313, 0.5015161037445068, -0.41595155000686646, -0.4737926721572876, 0.09674589335918427, 0.2055596113204956, -0.15301969647407532, 0.13639819622039795, -0.26822009682655334, -0.2369699478149414, 0.15423618257045746, 0.08512098342180252, -0.5112673044204712, -0.152215838432312, -0.3894578218460083, -0.2794609069824219, 0.25740838050842285, 0.0706968754529953, -0.12208926677703857, -0.030523497611284256, -0.39098188281059265, -0.1496560275554657, -0.18248891830444336, 0.177390918135643, -0.06730227172374725, -0.2326263189315796, -0.39206913113594055, 4.01797342300415, -0.03446447476744652, 0.3783981502056122, 0.8288966417312622, -0.6276419758796692, 0.12700170278549194, -0.25669020414352417, -0.16328981518745422, -1.0211942195892334, 0.06960739195346832, -0.0570511594414711, -0.3145689368247986, -0.19481948018074036, -0.6282006502151489, 0.14509442448616028, 0.3475756049156189, 0.027685975655913353, -0.22116222977638245, 0.12082073837518692, -0.2689826190471649, 0.32191380858421326, 0.2867833971977234, -0.03624396026134491, 0.08660197257995605, -0.10004366934299469, 0.2703806161880493, -0.27392104268074036, 0.36129364371299744, 0.3158636689186096, 0.30526232719421387, 0.47874242067337036, 0.5263198614120483, -0.17459657788276672, 0.33318784832954407, -0.13252976536750793, 0.2600903809070587, 0.21931825578212738, -0.23276656866073608, 0.11721526831388474, 0.2553115785121918, -0.027242843061685562, 0.010671615600585938, -0.25664108991622925, -0.4036473333835602, -1.0617237091064453, -0.08981971442699432, 0.15804721415042877, 0.17885559797286987, -0.1882118284702301, 0.13424809277057648, 0.016534361988306046, -0.01758553460240364, -0.12964001297950745, -0.14010730385780334, -0.2735729515552521, 0.20376244187355042, -0.02863764762878418, 0.006080321967601776, -0.36731672286987305, -0.10315509140491486, 0.5849190950393677, -0.15150043368339539, -0.12340165674686432, -0.6239132881164551, 0.8491221070289612, 0.32662880420684814, -0.25075870752334595, -0.3164811134338379, -0.1807912290096283, 0.2629782259464264, -0.26927506923675537, -0.4556884169578552, 0.46105194091796875, 0.08445806801319122, -0.15849509835243225, 0.7444835901260376, 0.4928188621997833, -0.22336626052856445, 0.10771246254444122, 0.302970826625824, -0.038313575088977814, 0.4282141923904419, -0.3383447229862213, -0.24720929563045502, 0.3559565544128418, 0.0602731928229332, -0.7579395771026611, -0.1715351641178131, -0.15533536672592163, 0.007944434881210327, 0.11578444391489029, -0.10638026148080826, 0.8469236493110657, 0.036415502429008484, -0.015987280756235123, -0.4298493564128876, -0.9065490365028381, 0.059560149908065796, -0.07690010219812393, -0.4459152817726135, 0.37930840253829956, -0.30308231711387634, -0.18761634826660156, -0.6653993129730225, 0.16792303323745728, 0.14120325446128845, 0.03647588565945625, 0.45336467027664185, 0.03719073534011841, 0.18287941813468933, 0.1323772519826889, 0.4093659222126007, -0.036635540425777435, 0.021342791616916656, -0.0012690015137195587, 0.10483504831790924, -0.8023473024368286, 0.1153632178902626, 0.0681922510266304, -0.23936057090759277, -0.14766475558280945, -0.02983449399471283, -0.33379703760147095, 0.34362831711769104, -3.078575611114502, 0.14325012266635895, -0.28317874670028687, -0.4927496016025543, 0.1044781357049942, 0.3728671371936798, -0.04572831094264984, -0.015816140919923782, -0.4024210572242737, 0.015934735536575317, 1.2771624326705933, -0.3389964699745178, 0.20826315879821777, 0.17455816268920898, -0.336035817861557, 0.11877764016389847, -0.2362653911113739, 0.10744817554950714, -0.046797946095466614, 0.5874122977256775, -0.16258090734481812, 0.27110999822616577, 0.2250732183456421, -0.6314358711242676, -0.08911144733428955, -0.2804033160209656, 1.2419980764389038, 0.3829594850540161, 0.2633261978626251, 0.34120798110961914, 0.4540344774723053, 0.027238352224230766, -0.3726789653301239, -0.7349318861961365, -0.3166452646255493, 0.03689832612872124, -0.08782926201820374, 0.13201990723609924, -0.184107705950737, 0.2791506350040436, -0.5195761919021606, 0.36938610672950745, -0.3799301087856293, -0.15056367218494415, -0.49944570660591125, -0.2152256816625595, -0.014206118881702423, 0.12426383048295975, 0.11347073316574097, -0.11239862442016602, 0.31518077850341797, -0.1490987241268158, -0.14971663057804108, 0.6370233297348022, 0.1443931609392166, -0.27781373262405396, -0.5498743057250977, -0.15709780156612396, -0.16183340549468994, 0.19045917689800262, 0.15694163739681244, 0.6736276149749756, 0.42203742265701294, -0.028979957103729248, 0.15241479873657227, -0.26901260018348694, -0.061226777732372284, -0.420550137758255, -0.3768558204174042, -0.34210634231567383, 0.03881070762872696, 0.18088248372077942, 0.0030770115554332733, -0.3596563935279846, 0.5096719264984131, 0.3835514485836029, 0.2807155251502991, -0.08470351994037628, 0.017156578600406647, -0.012391753494739532, 0.19007167220115662, -0.14436402916908264, -0.4853767156600952, 0.2829311192035675, 0.0735028013586998, 0.16672398149967194, 0.08350422978401184, -0.8439196348190308, 0.2804930806159973, -0.5212843418121338, 0.35043811798095703, -0.13674396276474, -0.01331784576177597, -9.758025407791138e-05, -0.20934763550758362, -0.32306814193725586, -2.9147109985351562, 0.2599502205848694, -0.31320416927337646, 0.3503498435020447, -0.1790580451488495, 0.33364537358283997, -0.21904295682907104, 0.4008309245109558, -0.6045417785644531, -0.20718994736671448, 0.1378149688243866, 0.3760211169719696, -0.235964834690094, 0.3529493808746338, 0.03708675503730774, -0.08815410733222961, 0.4505167603492737, -0.6344786286354065, -0.36183950304985046, -0.4173874258995056, 0.0061752572655677795, 0.5238634347915649, 1.6465084552764893, -0.13368722796440125, 0.269309401512146, 0.1589515507221222, 0.09306582808494568, 0.31597936153411865, 0.24298664927482605, 0.08136028796434402, -0.17925548553466797, -0.09089016914367676, 0.3218955993652344, -0.11109285056591034, 0.0969102531671524, -1.0136557817459106, 0.040944963693618774, 0.2847211956977844, 0.32963109016418457, 0.06872489303350449, -0.010060854256153107, 0.3572981655597687, -0.218170166015625, 0.1783345341682434, 0.8847331404685974, 0.15244607627391815, -0.1374950408935547, 0.013156913220882416, -0.47028517723083496, -0.19705218076705933, -0.0780658945441246, -0.3374767005443573, -0.26300135254859924, 0.03516233712434769, 0.6388565897941589, 0.5469487905502319, -0.15367329120635986, -0.16120100021362305, 0.11985446512699127, 0.26364776492118835, 0.24038617312908173, 0.27221277356147766, 0.3747744560241699, 0.7180729508399963, 0.29049140214920044]\n","output_type":"stream"}]},{"cell_type":"code","source":"nearVector = {\n    \"vector\": query_vector\n}\n\nresult = (\n    client.query.get(\"Pdf\", [\"content\"])\n    .with_near_vector(\n        nearVector\n    )\n    .with_limit(5)\n    .with_additional(['certainty'])\n    .do()\n)\n# Print the result\nresult = result['data']['Get']['Pdf']\nprint(\"Query result:\", result)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T17:31:52.001086Z","iopub.execute_input":"2024-09-16T17:31:52.001520Z","iopub.status.idle":"2024-09-16T17:31:52.085020Z","shell.execute_reply.started":"2024-09-16T17:31:52.001482Z","shell.execute_reply":"2024-09-16T17:31:52.083801Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Query result: [{'_additional': {'certainty': 0.785978376865387}, 'content': 'That is why we need to look at the timeline since it can show when and where \\nthe file was created ,when it was accessed or modified, this information is \\nimportant in order to determine whether the accused just downloaded porno \\nfrom internet or it was created locally. \\n \\n22 \\n \\n3.4 ANALYSIS'}, {'_additional': {'certainty': 0.785978376865387}, 'content': 'That is why we need to look at the timeline since it can show when and where \\nthe file was created ,when it was accessed or modified, this information is \\nimportant in order to determine whether the accused just downloaded porno \\nfrom internet or it was created locally. \\n \\n22 \\n \\n3.4 ANALYSIS'}, {'_additional': {'certainty': 0.785978376865387}, 'content': 'That is why we need to look at the timeline since it can show when and where \\nthe file was created ,when it was accessed or modified, this information is \\nimportant in order to determine whether the accused just downloaded porno \\nfrom internet or it was created locally. \\n \\n22 \\n \\n3.4 ANALYSIS'}, {'_additional': {'certainty': 0.785978376865387}, 'content': 'That is why we need to look at the timeline since it can show when and where \\nthe file was created ,when it was accessed or modified, this information is \\nimportant in order to determine whether the accused just downloaded porno \\nfrom internet or it was created locally. \\n \\n22 \\n \\n3.4 ANALYSIS'}, {'_additional': {'certainty': 0.785978376865387}, 'content': 'That is why we need to look at the timeline since it can show when and where \\nthe file was created ,when it was accessed or modified, this information is \\nimportant in order to determine whether the accused just downloaded porno \\nfrom internet or it was created locally. \\n \\n22 \\n \\n3.4 ANALYSIS'}]\n","output_type":"stream"}]},{"cell_type":"code","source":"template = \"\"\"\nYou are a helpful assistant who answers questions using the provided context. If you don't know the answer, \nsimply state that you don't know.\n\n{context}\n\nQuestion: {question}\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-09-16T17:26:08.300119Z","iopub.execute_input":"2024-09-16T17:26:08.300549Z","iopub.status.idle":"2024-09-16T17:26:08.306588Z","shell.execute_reply.started":"2024-09-16T17:26:08.300511Z","shell.execute_reply":"2024-09-16T17:26:08.305311Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"chunk_size = 100  # Split the context into chunks of 100 rows\ncontext_chunks = [ _result[i:i+chunk_size] for i in range(0, len(_result), chunk_size)]\n\n\nstream=model.create_chat_completion(\n  messages=[\n      {\"role\": \"user\", \"content\": template.format(\n          context=\"\\n\\n\".join(result[0]['content']),\n          question=query\n      )}\n  ],\n  stream=True\n)\n\nfor chunk in stream:\n    print(chunk['choices'][0]['delta'].get('content', ''), end='')","metadata":{"execution":{"iopub.status.busy":"2024-09-16T17:32:03.988639Z","iopub.execute_input":"2024-09-16T17:32:03.989133Z","iopub.status.idle":"2024-09-16T17:36:21.283479Z","shell.execute_reply.started":"2024-09-16T17:32:03.989070Z","shell.execute_reply":"2024-09-16T17:36:21.282264Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stderr","text":"Llama.generate: 40 prefix-match hit, remaining 886 prompt tokens to eval\n","output_type":"stream"},{"name":"stdout","text":" The main idea of the provided text appears to be a discussion about a time when a file was created, accessed, and then lost or deleted. The context suggests that the file was important, and its loss caused some inconvenience or difficulty. However, the text does not provide enough context to determine the exact purpose or nature of the file.","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}